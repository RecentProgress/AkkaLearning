怎样为股票聚类呢？想了一种算法，先试试

Maven 3.0不鼓励systemPath，如果想要依赖一个本地的jar包，最好的办法是起一个单独的project，里面只做一件事：把放在lib目录下的jar用maven-install-plugin安装到本地仓库。Project的标识可以与install时的配置完全一样。

关于local的jar，最终的方案是建了一个统一的libs.local项目，专门用来自动安装这些jar到本地仓库。例子可见：https://github.com/dcaoyuan/nbscala/tree/master/libs.local

AVRO作为一个数据交换协议的同时，也定义了同样的数据存储格式，它是可被diff的，因此，我把它作为一种DBF文件的替代，加上ID域后形成可关联的基础数据存储格式。它既可用git来同步，也可通过AMQP等协议传输，还可以当作SQL数据库来查询。在AIOTrade开源项目中有一系列相关的Scala实现。
更妙的是，利用Scala语言的能力，我还把它用来定义远程调用API的规范，比如： val SubscribeReq = Evt[(String, String, String)](3000, "userId: String, sessionId: String, topic: String") val SubscribeOk = Evt[String](3001, "topic: String") Evt是一个类，它还可以自动生成这些API的文档。

另一个用AVRO定义RPC API的例子：val QuotesResp = Evt[Map[String, Array[_]]](4002, "vmap", schema = """{"type":"map","values":{"type":"array","items":["null","long","double","boolean"]}}""")。在调用和返回时，用Scala的pattern match可以很简便地处理。Evt类可以见AIOTrade的lib.avro包。

你可以看里面的代码import进来的东西。实际上有三个主要的模块：lib.math、lib.securities、lib.indicator，看懂这三个核心模块，剩下的主要是各种扩展了，至于模块的一些代码为什么长成这样，一时半会就说不清了，总之是考虑了很多因素，然后又改变过一些想法，以后也可能还会变。

我这次的Bug是由异步并行运行的Actors等待一个状态的切换时导致，实质是有可变状态的并行程序很容易引入Bug。函数式编程在这方面不那么容易犯错（因为不维护会暴露的可变状态），但目前纯函数编程在计算效率方面又需要取舍。这个困局对人的能力来说本质上无解，由此Bug也会层出不穷.

其实这两年我改造和写了很多Scala的库，都以开源的形式集成在AIOTrade平台中，里面有很多设计还是挺有意思的，包括从Circumflex改造的ORM框架和这几天微博里提到过的AVRO的应用，AMQP的基础库，NIO库，代数算法库等。等我把手头的半自动“印钞机”投入使用后，可以抽时间介绍其中的一些设计。

2010年初我开始用Scala把AIOTrade改造成一个大型的高性能分布式并行计算和服务平台，这个过程用了1年半的时间。我认为它是目前国内计算能力最强的金融平台。从今天起，我打算零敲碎打地对这个平台的设计做些介绍。

AIOTrade 系统分为“计算中心”及“服务中心”，“计算中心”负责对全市场的数据、指标进行实时计算；“服务中心”则对外提供数据服务。一个“计算中心”可以服务多个“服务中心”，“服务中心”可以是在本地，也可以在远地。

计算中心负责接受海量的实时数据并完成成千上万个指标的实时计算。计算采用MapReduce策略，全市场的证券被分配到若干Mapper节点做实时单证券计算，并使用Reduce节点做规约计算（跨行业、跨板块等需要横跨多个证券的计算）。

“服务中心”不做计算，而是维护一个分布式缓存，所有数据从缓存中取出。对于不在缓存中的数据，“服务中心”通过RPC调用从数据中心获取历史数据，并订阅“更新数据”和“快照”。“更新数据”将合并到历史数据中。“服务中心”将实时转发从“计算中心”订阅的“更新”数据和“快照”数据。

“计算中心”和“服务中心”采用AMQP消息机制对外对内提供服务，主要提供三种类型的对外接口：1、“历史”数据服务，采用RPC请求/相应方式；2、“更新”数据队列，采用发布/订阅方式；3、“快照”数据队列，采用发布/订阅方式。

计算中心”和“服务中心”的对外接口是一致的，因此一个“服务中心”也可以作为一个更高级别的“服务中心”为次级的“服务中心”提供数据服务，从而形成可级联的“服务中心”。这些“服务中心”从黑盒的角度看完全一样，并且与“计算中心”看来也一样。

每个节点中的时间系列数据、包括行情和指标均设计为Actor，这些Actors将由系统的调度器自动调度到空闲的线程上计算，而线程将自动分配到多CPU。线程由线程池自动管理，系统将根据当前负载自动调整线程池的大小。每台PC服务器可以支持上千个线程，而可支持的Actors总数则可达百万级。

每个Actor均具有自己的消息信箱，并可发布/接收其他Actor的消息。Actor的可为外部辨识和利用的行为及状态完全由异步消息驱动，避免了同步锁带来的瓶颈及开销。通过AMQP消息机制，Actor发布/接收的消息扩展到了JVM外，从而使分布在其它节点上的Actors与在同一JVM内部的Actors具有完全一致的协同机制。

通常一个系统的架构至少要从实体关系层、业务逻辑层和表现层等层次考虑。万丈高楼从地起，实体关系层（或者说数据模型）永远是最重要的。对一个项目，我通常会首先花一两个月的时间对实体关系做仔细的分析和设计，而其要点是实体及关系的设计要用一条清晰、简洁的关系脉络将各实体间的关系表现出来。

所谓实体关系的清晰脉络，就是要找到若干核心实体并围绕核心实体来构造关系，非核心实体之间的关联尽量通过核心实体来实现，避免随意的相关。这样的设计通常会导出若干聚集的实体团块，团块内部关系密切，团块之间关联简洁。这样设计的好处是既符合实体的现实关联方式，也利于在实现分布存贮时分割。

我对实体关系设计的一条标准是：当需求变化时，必须能在几分钟内想到在什么位置插入、删除或调整实体，且必须几乎不影响整个实体关系脉络。证券系统的实体关系其实很简单，因此，我附了以前咨询的一个项目的实体关系图做例子（图的尺寸较大）。

除非存在迫切、严重的性能问题，尽量不要把团块A中的实体a与团块B中的实体b直接关联，而是应该通过a->A0->B0->b的路径关联（A0和B0分别是团块A和B的核心实体），要记住，保持一个脉络清晰的实体关系比一点点性能提升带来的好处要大得多。不要为了写SQL时能少输入几个字符而破坏了清晰的逻辑。

这样设计的结果，你可能会发现*核心*实体映射到数据表后更象一个记录了本团块内实体的目录，这样的设计是正确的，因为，一、另一个团块内的实体如果想查找这个团块的实体，首先就是查这个目录；二、在分布式系统中，目录是最重要的；三、一个层次化甚至分布式系统的核心构架就是一级一级目录。

果我有一天全面选择JavaFX，是因为它能很好地满足我的需求，而且与我原来的代码、设计有继承性。当然我是喜欢折腾的人，与Erlang怪人Joel Reymont有得一比。
@邓草原
有人如能整理下JavaFX的由来变迁，会是很有意思的题目。与Swing当初匆忙推出然后修修补补不同，FX的目标、设计和实现一直在变动和调整中，经历了很多取舍和较长时间，反映了在跨平台跨网络(CS/BS)的情况下业内在UI的适用性上的挣扎。直到现在看好JavaFX的还是聊聊无几，与Swing刚出时的热度形成大反差

早期的系统论者常说“整体大于部分之和”，这句话的内涵一直很模糊。刚想到一种解释：在一开始，整体其实等于部分之和，或者说，所有状态都是均衡的，然后某种迭代开始了，迭代通常伴随着选择，状态在迭代中不断变化且被选择导向某种有序的状态，形成有结构的联接，整体开始大于部分之和。

想说的是“整体大于部分之和”背后隐含了一个迭代和选择的过程，这个过程还表明它伴随着与外界的输入输出，整体的功能由此产生。迭代还与“鸡生蛋，蛋生鸡”的问题有关。随着现在越来越多的自组织现象被计算所模拟和应用，有关系统的观点开始逐渐变得清晰。

一个系统最严重的失灵是价值判断出了问题，因为价值判断是选择机制的核心，这种失灵导致它不再能够淘汰坏的东西，甚至相反，坏的东西获取资源的权重反倒不断增强，最后导致系统崩溃。这类似于或者就是癌症，这时可能要宣判这个系统只剩几周、几年或者十几年。

很多人只看到Scala提供了这个那个语言特性，也常拿各种新生语言来比较，这个那个也有了，殊不知Martin其实是个逻辑性非常强的人，或者说是个哲学家。我常拿“一致性”来形容Scala语言的设计思想，处处可见的“一致性”，内在逻辑和表达形式的“一致性”。
是你那篇《对Java的修正和超越-Scala的一致性和简单性》么？ 以前看过，经你这么一说还需再体会体会。

Scala 2.10提供了macro的新特性，这里有一个很好的适用场景实例：把for loop优化成while循环：https://github.com/ochafik/optimized-loops-macros

Listener模式在Java中大量使用，在Scala中能不能全部替换为Actor模式呢？在用Scala重写AIOTrade时，我这样做了，不过，使用了一个稍作修改的轻量级Reactor，和Publisher一起替掉了原来代码中的所有Listener模式代码，好处嘛，异步＋分布，很容易扩展来处理分布式的事件。代码在lib.util的actors包。

它的Parser代码我倒没有细看，不过似乎是在手工写的BNF Parser基础上。我现在比较喜欢Parsing Expression Grammar (PEG) + Rats! Parser Generator来解决问题。比如Scala插件中的词法Tokens都是用它实现的。

Martin在Scala 2.10中重新设计了reflection库，这个库可以说最大程度地开放了Scala在编译过程中收集的所有信息，实际上可以说是编译器本身，但经过仔细考虑和设计过的层次，使用者可以按照自己需要的程度来使用它，略过不想了解的东西。另一个一致性：编译库与标准库的反射部分的一致性。

关于新的反射库，我可以猜一猜Martin。标准库里原来提供了一般意义上的反射API，但Martin既是Scala的设计者，也是标准库、编译器甚至IDE的代码的主要作者，他逐渐意识到，为什么要专门写一个反射库呢？把编译器产生的所有信息用同一套代码按层次开放出来不是更好吗？－－只有亲自编码才会有这些体验。

就像Lisp的威力之一来自“代码就是数据”，JavaScript在Web应用上的威力之一来自它对DOM树随意游走和处理的能力一样，Scala的新反射库，实际上提供了Scala对AST树的完整自省和游走的能力，以及把作为AST树的“静态”代码本身当作可处理的数据的能力，我们不妨看看它将会带来对哪些问题的简化。

我们需要一个尽量节省内存的ArrayList来存贮double，所以不能简单地用Java的ArrayList或者Scala的ArrayBuffer，因为它们存贮的是对象类型。Scala中可以用'@specialized'来避免自动装箱拆箱的消耗，但会额外多存贮一个基本类型的数组。因此我写了一个改造自ArrayBuffer的ArrayList来实现自己的需求。
这个定制的Scala ArrayList源码在AIOTrade的lib.util的collection包中。
：@specialized 会额外多存贮一个基本类型的数组，能说一下细节么？
这里有一个翻译得不错得博文:http://blog.csdn.net/nethibernate/article/details/5755423

Scala 如果object中的一个val量在初始化时不是简单赋值，而是需要做一些操作，比如从数据库加载东西，那么一定把它定义为lazy val，这样的object才可以任意引用。

Scala Case：Class(n:p1, d:p2) 中n/d这两个参数的生命周期有多长呢？是仅作为构造函数的一个参数呢？还是会成为实例的一个字段而与实例长存呢？在最近的一个应用中，因为参数对象是一个很大的对象，希望尽快GC掉。而对象的生命周期则很长。Scala在处理Class Parameter时情况还是有些复杂。
如果在非构造过程中引用了n或d，则n或d会成为实例的一个私有字段，否则，只是一个构造参数，scalac足够聪明能判断是否需要把它编译为实例的字段。你可以javap -private看成员。例如class A(n:String) {print(n)}，这时n只是一个构造参数，而class B(n:String) {def m=n}则会因为方法m引用了n而成为字段.

这个复杂性本身还是源自现实世界的复杂性，逻辑上这些选项本身就存在，Scala没有带来更多也没有减少。我认为普通程序员使用Scala需要IDE，IDE可以提示这些问题。对Scala各种Corner case的总结，可以通过一个检查程序来预警。Scala相应工具的开发还有很大的空间，新的反射库可以帮到这些工具的开发。

通常我会设计一个接口，实现这个接口的Actors在接到查询请求（消息）时汇报自己的状态。对于重要的Actors，则会让它主动定时汇报自己的状态。这些需要汇报状态的Actors注册自己的RPC通道，或者广播自己的状态，通过RabbitMQ实现分布监控。当然，也许akka在实现一套统一的机制，但自己实现也很简单。
@王在祥
在akka中，如果有成千上万的actor，或者是在分布式环境中，应该如何来对系统的质量、效率进行监控呢？如果有一个强大的Console管理actor，那么应用akka来做分布式计算应该是一件既简单、又强大的事情。继续学习中。

统一的机制有意义。但过去等不及akka，自己写了一批基础工具。等什么时候有时间回头看看现在的akka实现得怎么样了。

写手工的deep clone，真心觉得immutable对象的好处，因为这些对象的实例你不需要再clone，直接引用就是。

Fortress的语法是用Parsing Expression Grammar (PEG)定义的，我就是从这个项目里第一次了解到PEG。Packrat parser则可以高效解析PEG语法，现在的Scala也提供了相应的支持库，可直接定义和解析DSL语法。我用PEG定义过Scala的语法，这些定义在https://github.com/dcaoyuan/nbscala/tree/master/scala.core/src/main/java/org/netbeans/modules/scala/core/rats，nbscala现在用它生成Tokens。

PEG和Packrat parser不区分词法和语法，是一次性解析的，而不是像很多解析器那样先词法扫描出Tokens，然后再在Tokens的基础上语法解析生成语法树。不过对于NetBeans这类编辑器来说，快速解析出Tokens用于染色和示错等就很重要了，所以我也用PEG来同时定义和解析Tokens，估计这么干的我是唯一一个。

说这么多PEG，其实就两个字：喜欢。PEG可以描述像Scala、Fortress这样复杂的语言，还是很强大的，如果你想定义自己的DSL，不妨试试。如果你恰巧也用Scala，那么不妨试着用scala.util.parsing.combinator.PackratParsers来直接定义和解析PEG。

Scala 3可能包括哪些新特性呢？先看一下邮件列表里的Toward Scala 3话题http://comments.gmane.org/gmane.comp.lang.scala/27185，等有时间我或者谁谁可以翻译和讲解一下。

如果再写编译器，我会用前面推荐过的PEG，因为它的表达能力够强，且对它的解析过程研究得也比较透了，也有不错的产生器，算是表达能力和效率之间的一种平衡。至于类型系统，计算领域的概念非常多，也容易互相借用，但关心其在各自场景下准确定义的人却不多，所以很佩服那些想把这些理论体系研究透的人

PEG适合非常复杂的语法,SQL这种简单语法更不在话下,不过效率和内存就可能是问题了。H2的作者应该是手工写的Parser,主要考虑效率等因素,当然一般人写Parser会从一个自动生成的Parser入手改进。PEG有AST,可以跳过词法。词法Token在大部分情况下用不着,真要用,多生成一个词法Parser就是。

请教@邓草原 ，最近需要一个简单的DSL Parser，之前你提到过PEG，花了点时间看了一下资料，我的理解是PEG是类似BNF的语法定义规则，Packrat parser是根据PEG构造Parser的方法，而具体的实现则有不同语言的版本，对吗？我找到parboiled这种定义内置在代码中的，但库有点大，轻量级的Java实现有否推荐？
Rats 见 http://cs.nyu.edu/rgrimm/xtc/rats-intro.html

PEG心得[1/3] PEG是类似BNF用于描述形式语言的一种文法规则，是一种自顶向下的文法。形式上与基于BNF的CFG（上下文无关文法）非常类似，但又有区别。PEG不允许二义性，PEG中会明确的选择第一个匹配到的语法元素，而在CFG中却不一定。
或者说PEG的选择路径是有优先权的，即按指定顺序优先匹配。

PEG心得[2/3] 基于PEG的解析器有三种实现方法，1. 递归下降分析法，简单直接，但时间消耗很容易以指数级增长。2. Packrat parsing，任意PEG规则都能在线性时间内完成，但空间消耗大。3. 经典的LL/LR方法，能够兼顾时间空间的消耗，但可支持的语法能力受限，不支持PEG中无限lookahead的能力.
Scala 2.8以后有一个Packrat parser combinator的实现，以库的形式作为工具提供，我以前用它写过HTML和JSON的参考实现，有时间找找看。

PEG心得[3/3] PEG的Java/Scala版解析器实现 1. Rats! (http://cs.nyu.edu/rgrimm/xtc/rats-intro.html，Parser生成器，文法规则方面对PEG有所扩充，写法上类似Yacc，可根据定义生成Parser代码 2. parboiled (https://github.com/sirthias/parboiled/wiki 非生成Parser代码，而是在通过代码代码中定义文法规则，有详细示例
在写Scala和Erlang的NetBeans插件时，就是用Rats!来生成词法或者语法的解析器。软攻狮出来总结，俺支持一下。

比起不能在文法规则定义时就解决问题而被迫嵌入代码，PEG还是挺优美的，当然得花些时间掌握。 //@软件攻城狮:是的，正因为有优先级的设定，因此可以避免else悬垂这种CFG需要从语义层面解决的问题，但是也造成了需要特别注意消除左递归，但其实CFG也有左递归，总的来说还是非常好的东西
PEG心得[1/3] PEG是类似BNF用于描述形式语言的一种文法规则，是一种自顶向下的文法。形式上与基于BNF的CFG（上下文无关文法）非常类似，但又有区别。PEG不允许二义性，PEG中会明确的选择第一个匹配到的语法元素，而在CFG中却不一定。
Erlang的PEG语法定义(Rats!版)可以在这里找到：http://hg.netbeans.org/main/contrib/file/tip/erlang.editor/src/org/netbeans/modules/erlang/editor/rats
实际上对于Rats!本身，我也写了一个语法定义，见：http://hg.netbeans.org/main/contrib/file/tip/rats.editor/src/org/netbeans/modules/rats/editor/rats

对@邓草原 说：请问Scala vs Erlang，你有什么看法
在QCon Beijing 2010有过一个演讲《并发需求下的Scala及Erlang比较》，网上应该能找到。另外在我的英文blog上有一些零散的看法：O网页链接。具体还要看你的应用场景。
畸角旮旯的问题在scala in depth里讲了很多，我正在翻译。

https://github.com/CSUG/real_world_scala ， 哥闲的无聊的时候零零散散添了些内容进去，给对Scala感兴趣的初学者看看吧，起《Real World Scala》这个名字本来是想将Scala这个生态环境里那些用于生产的框架，组件，产品等介绍给scala世界之外的人，呵呵

在面向对象（OO）看来，譬如“人”此类对象在世间有很多很多实例，生命周期完毕时被GC。在函数式编程（FP）来看，则是“凡所有相，皆是虚妄”，何况“人”这种副作用乎。总而言之，FP，是出世，OO，是入世。

每次我怀疑问题是不是来自Scala的Actor实现时，都证明问题是其它原因导致的，尤其是我使用弱引用实现的Publisher/Reactor时，很容易忘了要有地方一直持有这个Reactor（否则就会被GCed）。

老蔡这段描述逻辑也有点问题，一会动态一会静态，容易把人搞糊涂。确实，Type Inference须经(预)编译才有用，不管用在动态还是静态类型语言。对静态类型，少写代码；对动态类型，可额外检查。//@老赵: Type Inference是为了让人少写点类型吧 ...，而且这里谈Type Inference本来就是编译期的概念 ...
@蔡学镛
动态类型代码好写，但有执行效率问题，也不能在编译时提前发现错误。所以过去十年流行 Type Inference，让我们用动态类型写法达到静态类型效果。不过 Type Inference 不能完全达到动态类型效果，且过程往往很耗时（如果是编译式语言也就罢了），所以最近 Optional Type 多了起来，例如 Dart。

或者这样说清楚点：对静态类型，加Type Inference，可少写代码；对动态类型，一是可借助Type Inference对类型做一些额外、自动的分析和检查，或是可以用Optional Type，多写代码，来增强分析和检查能力。

系统的可靠性其核心是能从仼一崩溃点恢复至原来的状态。状态可分为活动的状态（当前）和已固化的状态（历史）。我设计系统时，活动的状态总在内存中并发布到消息系统，这样任何订阅这些消息的系统都可作备份系统；同时只有已固化的状态才写库以备回溯。——怎样简化系统的设计。

当状态的顺序重要时，接收消息并被驱动的Actor在内部实质上是串行处理的，以保证状态的顺序和无并行冲突。而在宏观上看，大量的Actors却是在并发活动，各自改变状态并发送消息了。我把这种Actor称作可并行的最小颗粒。并行系统的设计要旨是找到这个最小颗粒并设计为一个个的Actor

邓草原：回复@fantiny:一个完整的事务可看作一列顺序发生的状态集，当然可用Actor来处理。极致时甚至可以对每次原子事务Fork一个Actor，且把每步状态记录在内且发到消息系统以让远端另一个Actor热备，最后在事务完成后销毁它。当然总有各种具体情况要处理，但活用Actor是并行分布系统的有效手段。
fantiny：我之前设计的工作流就是严格区别按照这种方式做的，但是牵涉到事务的时候，事务本身是另外一个层次的切面，所以事务相关的我认为还是有单独的actor通过事件接受后统一管理比较好。这样的话，就会出现多维度的设计。

回复@fantiny:一个完整的事务可看作一列顺序发生的状态集，当然可用Actor来处理。极致时甚至可以对每次原子事务Fork一个Actor，且把每步状态记录在内且发到消息系统以让远端另一个Actor热备，最后在事务完成后销毁它。当然总有各种具体情况要处理，但活用Actor是并行分布系统的有效手段。 //@fantiny:

因为是Actor，它始终有一个活动的loop，所以潜意识中比较容易认为它总是在那里，而实际上当没有其它实例引用它时，这个可怜的被忽略在某个角落的Actor，是会被GCed的。

对于一列要保证顺序的状态，当然由一个Actor处理最妥，这些状态的边界可以是这个Actor的生命周期。//@邓草原:回复@fantiny:一个完整的事务可看作一列顺序发生的状态集，当然可用Actor来处理。极致时甚至可以对每次原子事务Fork一个Actor…

我们的系统如果崩溃，在热备系统接管的同时，重启崩溃系统的动作无非是两个：1、Load history，把需要的固化的状态（数据）加载进来；2、Catch up，从消息系统中顺序取回活动的状态，并顺序重演一遍，这样总会、自然地追上最新的状态。
2 catch up 部分要怎么来实现呢，topic消息模型的话，也无法为没有做持久化订阅的客户端保留消息呀，如何才能实现在崩溃以后能够从正确的位置开始顺序的取到需要的所有消息呢？
这就是设计问题了，Topic的消息应该只是快照性质或者无关重演的，其余的当然要专属订阅。其实设计时仔细考虑哪些状态可以固化后存盘，需要重演的状态可以大大减少。正确位置通常与时间戳有关，也不排除其它的设计。
目前主流的消息系统好像都没办法原生的去支持按时间戳获取订阅，并且能够智能的清除掉以完成事务的消息，像RabbitMQ可以在一个事务完成以后并将系统状态持久化后主动地去purge一次对应的队列，以此来保证队列中的消息都是最近一次固化以后的，JMS模型的好像就没办法了
具体问题具体处理，总有解决办法，关键是设计合不合理，合理的话就应该逻辑清晰、简单，否则就推倒重来，我就一直这么干。

强调一下，订阅消息系统发送的活动状态的动作是启动时就做，接受后都由Actors自己暂存，待历史数据全部加载完毕，再开始重演，重演完毕，追上最新状态后，就是一个完全就绪的系统了。这里具体的场景当然需要做仔细的考虑和处理。
@邓草原
我们的系统如果崩溃，在热备系统接管的同时，重启崩溃系统的动作无非是两个：1、Load history，把需要的固化的状态（数据）加载进来；2、Catch up，从消息系统中顺序取回活动的状态，并顺序重演一遍，这样总会、自然地追上最新的状态。
目前的系统中有上百万个并行的Actors，经过仔细但简单的设计后，一切正常。

关系模型对事物的描述仍然是最完整和合理的，问题在于关系数据库本身目前成为了瓶颈，尤其是在分布式的环境下。不过随着内存越来越便宜（比如即将看到的16G一条的），从关系数据库预加载到内存，以各种数据结构的形式存在其中，辅以好的数据分割设计，仍然是我最看好的机制。当然要在合适的场景下。

其实最合理的cache就是实体对象实例本身，这就涉及到如何处理好实体和关系模型的映射，既然我认为关系模型是最合理描述了实体的，当然持久化的数据以关系模型保存最合适了。

说得更多点，其实就是关系模型<->实体对象实例<->序列化，数据的转移无非是围绕这几个方面。我的选择很简单：mysql<->改造后的circumflex orm<->Scala对象<->avro，这里avro还同时被我抽象为一种简单的“关系数据库”，通过git来同步基础数据。

回复@fujohnwang:比如证券的基础数据、除权数据等，每遇变化就export成一个个的avro文件，avro对diff是友好滴，这样就可以通过git来同步，而且是分布式的哟；然后在circumflex里写一个avro的jdbc驱动，客户端调用的时候不知后端是sql数据库还是avro，这样代码与服务端的完全是同一套。

与此同时，这些对象的avro也用来在不同的节点间传颂，还可以export成json、xml等等。总之，关系模型<->对象<->序列化，在这里和谐了，并且可以从此科学发展下去。

LShift的Lee Coomber写了一个小程序，可以显示RabbitMQ中的拓扑图：https://github.com/ljcoomber/rabbitmq-graphviz，底层用的是老牌开源绘图软件graphviz：http://www.graphviz.org/

我遇到过类似的场景，在单个Actor发布能力成为瓶颈时，处理办法是用一批Actors轮流（revolver）发送消息，而监听者listenTo(actors: Actors*)。
@扶墙老师
@邓草原 在Actor模型中， 如果我要将同一条消息multicast或者broadcast给下游大量的actor，除了顺序的foreach(_！m)， 有没有更有效的方式那？ （当然， 也不见得这种方式导致的latency就多么紧要，只是在想有没有更并行更有效的方式[嘻嘻]）
参考代码可见：https://github.com/dcaoyuan/aiotrade/blob/master/libs/lib.securities/src/main/scala/org/aiotrade/lib/securities/dataserver/TickerServer.scala 中的object TickerServer/

回复@王在祥:关于热升级，与设计相关，对于使用了很多状态的Scala对象而言，不像Erlang倾向于无状态，更要在设计时注意。我们系统中主要的功能像指标等都设计成了可以热替换，但如果数据Model发生大的变化，就难免要靠双机切换来完成升级了。不过我们的数据Model设计得不错，到目前没有发生这种。
@邓草原
经过几年的开发，终于有了一个完整的，从行情落地、到指标计算、到回测、到与柜台交易系统对接，全部就绪的自动交易系统，而且是分布式、并行的。行情和计算平台从去年5月最后一次重启后，到现在已经不间断地运行17个月。从接触Erlang到现在的Scala，一路收获实在太多了。
最近准备评估一下akka。两年前觉得他们还不够成熟。初步印象，akka的设计对有无暴露状态的actor界定较严格，便于actor“自由地”在分布环境下迁移；还有一些设计也不错，可以替换我自己实现的一些代码。
是各有进步。选Scala是为了计算效率和OO/FP，DSL、UI等。其实后台的消息系统是Erang的RabbitMQ。
你不用actor，就可能用了thread。在我看来，除了其它的好处，actor主要是引导你尽量设计无共享状态的并行/并发颗粒，所以actor又被称为一种编程范式。

看着akka想着EJB。Enterprise Beans，尤其是Session Beans，EJB当初想解决的问题也许会在Actors这个更轻量、尤其是更合逻辑的角度找到大部分答案。至于J2EE，OTP和akka也更理所当然些。看问题的角度对了，才不会通过制造问题来解决问题。


这也提供了一条思路：如果你的系统已经被困在E-Beans里，akka或许可以帮你对应着跳出来。
@邓草原
看着akka想着EJB。Enterprise Beans，尤其是Session Beans，EJB当初想解决的问题也许会在Actors这个更轻量、尤其是更合逻辑的角度找到大部分答案。至于J2EE，OTP和akka也更理所当然些。看问题的角度对了，才不会通过制造问题来解决问题。

在AIOTrade中，设计范式是Everything is actor，当然，为了性能，这些Actor实际上是实现了trait Actor的普通对象，这样我可以选择哪些接口（方法）是直接（同步）调用的，哪些是经由消息驱动后异步执行的。但akka的actor不允许这样的设计，只有经由消息驱动的（Actor）或异步的（TypedActor）的接口。

我想到的解决方案是：对于性能可接受的，直接迁移成akka的actor；对于性能重要、调用频繁的，改成每个对象都包含一个Actor。不管怎么样，akka的pure actor，让我把对象的设计得区分得细致了，这样再出来的系统，把时间维度渗透到了大部分对象的设计，当更健壮，值得一试。

这样其实感觉并不舒服，因为它退回到了我过去的设计，而且，一致性没了。不行，我得再想想。

回复@我是来测试的:如果是性能特别在意的接口，多花些时间仔细设计也是难免的。其实在AIOTrade中，这种情况下我也会上锁。 //@我是来测试的:回复@邓草原:这种混合式设计, 不乱么?

akka的pure actor，让我静下心来再好好想想关于“状态”的问题。首先，会把原来在iteye的两篇零散笔记搬到微刊。

【FP OO 杂想】（2007年2月写的东西了）这是有关OO和FP的杂想，断断续续的……一、关于对象1、FP中的对象Erlang：对象Object就是原基数据以及原基数据的组合，如果说Object还有Type的话，那... --发布到微刊《不可计算》

【Erlang里的OO和Java里的OO】(也是2007年2月写的东西了)首先，这里OO中的Object仅指包含可变状态这个角度的Object，暂不涉及有关OO的多态、继承等概念。一、Erlang的OO１、保存在函数调用栈中的状态Erl... --发布到微刊《不可计算》

300亿条数据，用HBase，随机分配，在节点<100的时候，由于业务的性质，缓存命中概率几乎为零，查询的瓶颈全部落到了硬盘IO。假设硬盘要承受200r/s，100个节点的每秒查询性能会受制于200*100=2万/s；对批处理的情形，而我们又有rawKey分布的先验信息，这时做分组，则可设计小key顺序分布跟随大key随机。

试了一下akka remote actor最简单的例子，需要akka发行包里的四个jar：akka-actor, akka-remote, netty和protobuf-java。

Spanner在分布式数据库设计的关键环节，包括ID、层次、事务等，把握到位。这篇文章总结得也不错。//@CSDN杨爽:O网页链接，从Google Spanner漫谈分布式存储与数据库技术，程序员杂志2012年11月刊上的这篇杂志也不错啊。
@陈利人
透視Google資料庫全球同步的祕密：Google Spanner系統 O网页链接 O网页链接

要精心设计出最简洁合理的“组合”数据来进行分析，这些数据量应该控制在能载入到数十（百）台合理成本的PC服务器内存中，比如，目前约258G内存/台，10台能载入2T的数据，成本在一两百万左右。载入的数据组合成业务对象，并全部设计为可并行计算的Actors，以用CPU的计算能力换取空间。

数据分布在各节点的内存，这些节点只负责做Map运算，可以通过RabbitMQ之类的消息机制来实现Reduce归并。Actor模式在这里可以带来非常多的好处，以至于我放弃了Hadoop的Map/Reduce机制，而采用Scala的Actor自己处理。最近思考另一个行业的大数据分析，发现在金融计算平台上的这些经验几乎可以照搬过去。

函数式编程的好处是不用保存状态，如果CPU的计算能力够强，这意味着所需的内存空间可以很小。从原生数据出发，组合好合适粒度的中间数据，就可能以较低的成本实现大数据的实时分析。在AIOTrade中，这样合适粒度的中间数据只设计了两种：分钟线和日线，其余周期的数据和指标都是由此派生（计算）而来。
数据的瞬间生灭主要发生在函数的调用栈上。目前纯函数编程还只是一种理想，JVM也并不是为优化的，这确实是个好问题。//@空谷松籁:内存会更大吧？因为状态大多都以参数在传递，分配在栈上，会自动回收 //@fujohnwang:转发微博

相对来说，每一个Erlang进程创建之后都会有自己的PCB,栈,私有堆，垃圾回收机制简单，速度快。//@邓草原: 数据的瞬间生灭主要发生在函数的调用栈上。目前纯函数编程还只是一种理想，JVM也并不是为优化的，这确实是个好问题。//@空谷松籁:内存会更大吧？因为状态大多都以参数在传递，分配在栈上，会自动

我建议你把wikipedia上的Monad词条翻译一下 https://en.wikipedia.org/wiki/Monad_(functional_programming)， 这样算是有一个比较正式的中文的Monda词条。
@我是来测试的
翻译了一个介绍monad的BLOG, "感性认识monad", 意译得严重. 都忙过年了, 估计没什么人看. 我只好故意艾特几个人了 @邓草原 @fujohnwang http://blog.sina.com.cn/s/blog_62d8ec83010197im.html

回复@fujohnwang:1、现在的分钟数据已近5亿条，而最原生的tick数据量是其5倍，实际上每天的数据量至少有2G；2、系统一开始按关系数据库设计，一来是多年前的决定，二来是考虑SQL可能会满足尚未考虑的需求。但几年来的实践表明，按现在的分布式并行设计，复杂的单纯的SQL查询都以化解，以至可以取消了。
@邓草原
今天早上修复了几个sbt和NetBeans集成的bug，春节前的工作告一段落。节后两个月计划了几件事：1、看akka的代码；2、决定AIOTrade是否迁移到akka；3、决定AIOTrade是否从MySQL完全迁移到HBase；4、开始一个新的交易策略的开发。

编译器要编译自己用到的库（蛋鸡问题），所以尽量使用简单直接的类。Scala的交互编译器为了性能而使用了很多延迟求值的技巧，也带来了多线程访问时的竞争问题。我已经注意到这种冲突带来的AST偶然会出现问题，多线程居然也会困扰到Odersky，因为基于前面的原因，他不会在编译器中用Actor。（待续）
（续）直到即将发布的2.10.1，在交互式编译器中加入对访问时的线程的检测，在可能引起冲突的地方，只能通过编译器自己维护的一个线程访问，这个线程设计成了流水线，所有的任务排队串行完成（听起来象Actor），代码简单直接，有遇到类似场景的同学可以借鉴：https://github.com/scala/scala/blob/master/src/compiler/scala/tools/nsc/util/WorkScheduler.scala，https://github.com/scala/scala/blob/master/src/compiler/scala/tools/nsc/interactive/CompilerControl.scala

跟答已很详细。两个要点：1、编译器有条件比人的直观做更仔细的分析；2、match的情况多样，每种都要分别处理，对值的匹配是equals。实际上，如果你自己有把握，可以在返回值后强行加上asInstanceOf[T]，但编译器认为这要你自己决定。在编译器的升版中，还增加了很多基于逻辑的警告信息，但你自己做决定
@王在祥
@邓草原 草原兄，关于scala的类型推演，我在stackoverflow上问了个问题，不知道您能否给我一些帮助？http://stackoverflow.com/questions/15222398/why-does-type-inference-fails-in-this-case

akka的TypedActor中定义的方法是通过反射来调用，如果用JDK7的invokeDynamic/MethodHandle来实现，性能能达到满意的程度吗？这是我最近在考虑的问题。初步比较，MethodHandle耗时是直接调用的2.5倍，而反射则是15倍。2.5倍的时间还在可接受的范围内。随着JDK7性能的提高，我在用更多的Function Style。

Scalaz是一套函数式编程的Scala库（也许是周知了），实现了纯函数的Functor, Monad等类型及其相关的数据结构实例。我想介绍的是一篇不错的Scalaz的入门文章，是日本的eed3si9n写的：http://eed3si9n.com/learning-scalaz/Combined+Pages.html；正好也有一篇有关Functor, Monad的图文兼茂的入门文章：http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html

不错，转起.我是看了这四篇文章了解monad的: http://james-iry.blogspot.sg/search/label/monads

Jonas对actor的角色总结得不错。Actor可以替代：1、线程；2、对象实例或组件；3、回调或侦听者；4、单例或服务；5、路由、负载均衡器或池；6、JavaEE中的Session或Message Bean。

远古的函数编程期，理想世界的设计者们讨厌不能在一个纯函数内完全控制或者说只在这个函数内生灭的状态，他们又很不想引入“对象”这个“坏小子”，所以想出了一种方案：把函数及其上下文环境绑在一起，叫闭包，闭包吃进（捕获）外部环境的状态后就闭合成了闭包函数，这样就又可以把这个东西叫函数了。

闭包虽然不纯了，但总还是"函数"，而且，这是把捕获的外部状态控制在最小的作用域内的不错的方法。编译器遇到闭包时想优化的话就要打起精神来，把状态的作用域分析清楚。写代码的人也要知道，这是个闭包，不纯，小心副作用。

对象”这个概念的引入，对编程语境而言，就意味着可变和可交换/共享的状态全面地扩展、泛滥到整个世界，也就被迫引入诸如private/protected/public等一系列限制手段。从这个意义上说，闭包很伟大。//@Camel_Jong: 闭包确实很多时候简洁好多，不像C＋＋，动不动就要搞一种对象，麻烦多了。

标题为《Scala中的函数与闭包》，但对闭包没怎么涉及（Scala中的闭包是可以说清楚的）。先帮转，如有疑问可以后续提出。
@hongjiang_wang
下午分享的《scala中的函数与闭包》

闭包 在计算机领域，名词众多，且常借用数学、哲学、物理等学科的名词，难免会带来疑惑。以“闭包”为例，这个词或来自代数但涵义与现在编程中的习惯用意并不一致，更甚者，这个词现在搞得跟“函数”也有点不清不楚了。我曾想写一本Scala的书（不许问我进度），准备过一些不完整的素材，先放些在这。 Scala核心编程第二章

我是用Scala+AVRO自己定义的一套，参见：https://github.com/dcaoyuan/aiotrade/blob/master/libs/lib.avro/src/main/scala/org/aiotrade/lib/avro/Evt.scala
@王在祥
一直在寻找一种在服务接口中能够简洁、清晰的描述接口契约（类似于DBC或者DDD的Spec）的方式，最好能够规格化（而不是注释）、简洁（可作为文档）、简单（不要引入太多复杂的语言、语法），大家有什么好的推荐或者建议？

怎样用Scala写iOS应用？ 这需要一系列的转换：Scala -- scalac -> Java byte codes -- IKVM -> CLR byte codes -- Xamarin.iOS --> ARM x86 assembly。samskivert给出了一个例子：https://github.com/samskivert/ios-scala-demo

好吧，这又是一个Raspberry Pi和JavaFX的例子，这个例子是控制一个机器人：http://jperedadnr.blogspot.fi/2013/01/nxtbeefx-javafx-based-app-for-raspberry.html

系统或者实体，应该从不同相互作用的条件下的行为来描述。只有对其施加作用来观察它们的反应，才能知道它们是什么。——不过我走得更远些（Q）

量子（quantum）这个概念包含了：量化（测量）、取整…… 等等。

分布式架构重点是解决可扩展性，实际上反倒可能因为多出了很多状态而使得高可用性的设计变得更复杂了。//@动物庄园上校: 链接新鲜出炉，做了一些对当时场景的说明，欢迎批评指正。 http://edge.iteye.com/blog/1928413

上交所2013年日均有效报单笔数为832.7万笔（每秒约578笔），开盘头15分钟高峰期约占11.43%（每秒1058笔）。撤单笔数约占25%。假设要应付的最高峰值为1058x100约每秒10万笔，以现有的技术条件，对这10万笔做账户做实时校验是可能的。一种设计是每个账户均为常驻内存的独立actor，定时或实时更新。

用actor来对应每个账户，可以简单地实现并行和并发校验，并且因为异步实施，不会因为某个actor的行为故障或者异常阻塞其余的actors的行为。目前中国股市的开户数约为1亿，一台大内存的PC服务器足以容纳1000万个账户actors，10台应该可以把1亿账户的情况实时监控起来。

对于频繁交易的账户，可以通过智能算法自动迁移和均衡到分布的节点，也可以把不活跃的账户定期自动集中迁移到某几台节点。总体来说，对于大规模实时并发场景，Scala和Erlang实现的actor模式具有天然的优势。

回复@haofish:读取操作内存数据库时总得启动并发的线程吧，这样就还是绕不开行为（相对数据而言）的逻辑。 //@haofish:用内存数据库都能做到。。
@邓草原
上交所2013年日均有效报单笔数为832.7万笔（每秒约578笔），开盘头15分钟高峰期约占11.43%（每秒1058笔）。撤单笔数约占25%。假设要应付的最高峰值为1058x100约每秒10万笔，以现有的技术条件，对这10万笔做账户做实时校验是可能的。一种设计是每个账户均为常驻内存的独立actor，定时或实时更新。

我一直强调并发、并行与分布的一致性实现，实际上强调状态和行为的最小可并行的颗粒，这些颗粒除了可以随时调度到CPUs并行或者并发处理，还可以简单地主动迁移到分布式架构下的另一个节点。

实际上我一直没有时间来总结和说明白那个基于Scala和Erlang实现的“分布式并发金融计算和交易平台”的若干精妙之处，而且我确信其中的实现是可以推广到其它领域的。

在确定的应用场景下会被迫去思考解决的方案，然后发现万法归一，当然是新的“一”。//@动物庄园上校: 其实就像我上次说的，我更倾向于相信你发明了一个轮子，虽然有可能比他们的更圆，这很正常，看看你是不是愿意抽象一下开源出来？另外，可以下次你告诉我，我来执笔……
@邓草原
实际上我一直没有时间来总结和说明白那个基于Scala和Erlang实现的“分布式并发金融计算和交易平台”的若干精妙之处，而且我确信其中的实现是可以推广到其它领域的。

在内存里的actor的迁移，其实就是状态的迁移：在另一台节点new一个actor实例，确定迁移时点，复制状态过来，并接管驱动状态变化的message的queue就行了。//@黄颖劲: 我开始还以为是迁移actor，实际上还是数据的迁移吧!
@邓草原
对于频繁交易的账户，可以通过智能算法自动迁移和均衡到分布的节点，也可以把不活跃的账户定期自动集中迁移到某几台节点。总体来说，对于大规模实时并发场景，Scala和Erlang实现的actor模式具有天然的优势。

今天参加@Scala研学社 在SDCC上的活动，听@邓草原 的分享，很有收获，尤其是Actor在大规模分布式系统中的使用，shared-nothing实现，程序设计对垃圾回收的敏感性，还有极具新意的想法：Raspberry Pi与Actor组合成大规模分布式硬软件架构，及其在金融领域应用的可能性

1、actor的状态只受消息驱动；2、到处都是actor和可以到处迁移的actor；3、actor迁移到另一台节点只需复制状态，并接管相应的消息队列。其实可以跟现实世界人搬家做个类比：假设房子都是标配的，制度也一样，搬家就是人过去，然后更新通讯地址。

《互联网巨头为什么会“宕机”》，http://edge.iteye.com/blog/1933145

类型放前面、后面或者干脆单独拎出来放到代码主体外，可以看成是一种习惯偏好。至于在当今内存和CPU都够用的情况下，我不认为语言设计会再把是否容易parse作为主要目的之一。只要无歧义，有各种通用的或者蛮干的方法parse出来。现在的语言设计综合考虑的因素多，但最难平衡的是简单但又表达能力强。
@GeniusVczh
类型放前面就需要symbol table才能parse这只能证明go开发者的水平实在是太卧槽了 【为什么Go语言把类型放在后面？】@hooluupog：reddit上面的一条评论…

Parser仅是编译器Compiler的第一个阶段，编译器的复杂度与语言实现的复杂度有关。比如，强类型的语言可能需要进行类型推断和检查。编译器有一个非常重要的功能是对各种错误、包括潜在的错误进行细致的检查并给出准确的提示，以及在对可预测的执行过程进行判断后做各种优化等，这些都是很复杂的工作。

以Scala为例，一次编译需扫描n遍，含syntax、namer、typer、superAccessors、extensionMethods、pickler、refChecks、uncurry、tailCalls、specializeTypes、explicitOuter、erasure、postErasure、lazyVals、lambdaLift、constructors、mixer、cleanup、genicode、inliner、closureElimination等阶段

更进一步地说，现代编译器的设计，symbol table用来存放的信息已经非常多，比如标示名、类型、作用域、甚至行号等。实际上一切对后续编译有用的信息都可以围绕symbol table来一步一步地明确和充实，而symbol table中的信息不但可以给编辑器提供强大的支持，甚至可以放到标准反射库中提供给动态编程者。
@GeniusVczh
类型放前面就需要symbol table才能parse这只能证明go开发者的水平实在是太卧槽了 【为什么Go语言把类型放在后面？】@hooluupog：reddit上面的一条评论…

Scala的类型也是放在标识名的后面（以冒号分割），但整个编译器的设计中并没有取消symbol table，相反，利用symbol table集中存放了大量有用的信息。Parser在目前的编译器设计中几乎已是最简单的部分，其理论和手段也不再是C/C++时代的简单几样了，甚至通用的Parser生成器已经可以解析非常复杂的语法。

不同“理念”的parser可能使用不同的数据结构来完成解析。Parser的关键指标除了绝对的耗时和内存，还有与源文件的大小是否呈线性等。但语言的parser现已不应是主要问题和噱头了:-) //@GeniusVczh: 在parse完成之后，基本上都只有symbol table在起作用了。但是之前需不需要，这完全可以看spec来确定的。

几番讨论，我现在有点理解为什么这成为一个话题了。如果需要比拼极致的解析速度和空间，语言的spec当然会成为一个关键，诸如类型在前、在后也就可以拿出来说说了。不过，不同的语言设计目的不同，Go如果要去与C/C++全面比拼那就难免一场混战甚至狗血了。

不是那么简单。一个对事件进行收集和分析的大规模语义分析系统必须和行情数据系统融为一体，就像一个蜘蛛网，任何事件的异动应该是可以相互印证的。捕捉事件的蛛丝马迹也不仅仅限于事件发生的一刻，而应该有前后征兆。
@扶墙老师
事件套利里如果对事件进行语义分析然后判别交易方向，与基于统计模型的方式相比，是不是不好操作或落地？@邓草原 大叔怎么看？

对熟悉Actor模式的人来说，这是很自然的方案。不过，当需要实时监测的帐户数是1个亿时，还是挺有意思的一件事，况且，具体到这个场景，除了并发，还有分布，还有Actors的智能迁移...
@Scala研学社
Effective Akka第一章第一节第一个示例与 @邓草原 老师用Actor管理中国股市一亿帐号的设想如出一辙。

理解矩阵 http://www.vjianke.com/XYKGL.clip

当然，要看一下测试的配置：O网页链接 //@淘宝褚霸: 这个指标确实有点牛逼！
@邓草原
akka的首页上，关于High Performance有这样一段：50 million msg/sec on a single machine. Small memory footprint; ~2.5 million actors per GB of heap。这个可以作为使用actors设计系统的依据。
内存占用与你的actor中要保存的状态数量有关，400bytes是最简单情况下的actor，是实现一个actor的本身的代价，它很小，没错，400bytes。//徐赛馬：我用akka做了一个简单的c/s系统，让所有client每三秒发一个心跳，在亚马逊云平台测试1000节点性能，完全无压力，就是内存占用似乎没想象中那

具体实现的差异吧。都在JVM下，Java当然可以做到，只是Scala的代码更自然和简洁。其实我不是强调akka的性能，而是作为设计参考指标。//@动物庄园上校: jactor号称要快很多，有什么特殊原因吗，没时间看，求解

重入通常指同段代码未执行完毕时被另一X程再次进入执行，概念的适用范围窄些。//@analystqiaojie: 这事其实也就是个概念之争。某些场景下重入和锁有着相似的表现形式，其实锁也常用来解决资源重入问题。但终究是2个不同的概念，如果在讨论中不加以区分，就会导致鸡同鸭讲，造成很多不必要的误解。
@许式伟
ECUG 不求甚解的人是挺多的，他们往往会有些似是而非的见解。作为Erlang中国社区发起人，我觉得有义务纠正一个Erlang社区隐藏很深的误解：“Erlang服务器不需要锁，因为Erlang变量不可变”。一般来说，变量不可变不需要锁是对的。但Erlang服务器不需要锁却恰恰不是这个原因
当然，是否需要锁还要看是否在访问同一资源，是否可变。//@邓草原:重入通常指同段代码未执行完毕时被另一X程再次进入执行，概念的适用范围窄些。//@analystqiaojie: 这事其实也就是个概念之争。某些场景下重入和锁有着相似的表现形式，其实锁也常用来解决资源重入问题。但终究是2个不同的概念，
解决访问可变的共享资源冲突，加锁是一种方案，还有就是将访问请求全部排队，将并行在此转为串行，如actor//@老赵:A: 锁是用来解决重入的手段之一。B: 解决重入的手段就叫做锁。其实就是这点问题。
@许式伟 的看法和我的相近了，不过，他谈的是整个服务框架，我则从actor层次谈。//@邓草原: 解决访问可变的共享资源冲突，加锁是一种方案，还有就是将访问请求全部排队，将并行在此转为串行，如actor//@老赵:A: 锁是用来解决重入的手段之一。B: 解决重入的手段就叫做锁。其实就是这点问题。

解决冲突的方案之一：在合适的粒度串行化并行请求//@许式伟: 是的，这才是核心原因。如果我告诉你有个Golang的服务器框架，让你所有的请求都串行化执行，自然整个Golang程序不需要用锁了//@haman_karn: 不仅仅是因为变量只能绑定一次 用的并发模型也有关系吧 用receive 就相当于把并发的send给串行化
@许式伟
我说了两个误解：一个是单线程不需要锁这个是误解，这个以前讨论nodejs的时候谈过，有些人认为我在玩文字游戏；另一个是erlang服务器写代码大家不用考虑锁，是因为erlang变量不可变（注意我关注的重心是大家写代码有没有锁，不是erlang虚拟机）；第二个误解更深点
将所有锁一次性在这个消息队列中高效实现了，本身就很好了//@西祠响马: 使用队列将并行转为串行，只不过是重新实现了一个轻量的锁。锁不就是这么实现的吗？只不过大家嫌它重罢了。//@邓草原: 解决访问可变的共享资源冲突，加锁是一种方案，还有就是将访问请求全部排队，将并行在此转为串行，如actor
actor中(比如Erlang的process)已经实现了高效的消息队列，直接用就是。异步消息驱动下对共享资源的访问机制，实际上归一和简化了并行下的冲突解决方案。//@西祠响马: 从出错风险上来说，队列可能还更大。只不过学习门槛高，把更多的人挡在外面。 //@许式伟:其实队列更重一点，只不过队列不容易出错。
愿闻其详。//@许式伟: 为什么我说Erlang服务器框架是半吊子：轻量级进程模型核心是同步方式写程序降低负担，但Erlang蛮多设计又极其依赖异步消息，这是自相矛盾的。与其这样不如一上来就异步回调//@邓草原: 将所有锁一次性在消息队列中高效实现，本身就很好
new一个process请求数据库，这个process A.访问完回调；B.访问完发通知消息；C.干脆blocked成同步。//@许式伟: 最简单的例子：我响应请求代码中，访问数据库应该怎么写？//@邓草原: 愿闻其详。//@许式伟: 为什么我说Erlang服务器框架是半吊子：轻量级进程模型核心是同步方式写程序降低负担...
不会吧，至少在Scala中我没觉得有难受的地方。//@西祠响马: 应用级的代码用异步写就是个灾难。比如 Node.js。 //@许式伟:最简单的例子：我响应请求代码中，访问数据库应该怎么写？//@邓草原: 愿闻其详。//@许式伟: 为什么我说Erlang服务器框架是半吊子：轻量级进程模型核心是同步方式写程序降低负担...
要看是哪国的程序员了[嘻嘻]//@许式伟: 你猜猜大部分erlang程序员会怎么写？//@邓草原: new一个process请求数据库，这个process A.访问完回调；B.访问完发通知消息；C.干脆blocked成同步。//@许式伟: 最简单的例子：我响应请求代码中，访问数据库应该怎么写？//@邓草原: 愿闻其详。//@许式伟: Erlang
其实做IO时block成同步也没啥，重要的是它要在一个新的process中，它被block并不会影响整个系统，系统中总是还有大量的process在活动。对API，我通常会在异步回调函数基础上再包装一个同步的。//@邓草原: new一个process来请求，这个process A.访问完回调；B.访问完发通知消息；C.干脆blocked成同步。
看具体情况。所以我才提供两种函数。//@许式伟: 那唤起这个新process的人在干嘛呢？等还是不等？//@邓草原: 其实做IO时block成同步也没啥，重要的是它要在一个新的process中，它被block并不会影响整个系统，系统中总是还有大量的process在活动。对API，我通常会在异步回调函数基础上再包装一个同步的
Io is tough, let's go shopping.//@许式伟:等，不如自己发起io请求，所以我的理解是不等；既然不等，那gen_server就要为这次io多个临时状态，纠结呀//@邓草原: 看具体情况。所以我才提供两种函数//@许式伟: 唤起这个新process的人等还是不等？

实际上Erlang中把大多数IO都包装成了singleton process中的service，就是为了把对外部资源的存取请求串行化，以避免冲突。但这有时又带来singleton process的瓶颈问题，就像我以前在blog中谈到的，singleton process的性能不能随着cpu core数量的增长而扩展：O网页链接


可麦。//@淘宝褚霸: 回复@郑思遥:OMG，这么快，狂赞！中文版的哦，这下好多同学应该看着亲切了！ //@郑思遥:搞定 O网页链接 错误在所难免，请各位指正。原文通过Erlang调度原理的描述，论述了为什么Erlang能做到软实时，即满足低延迟，以及其他使用协程的语言为什么做不到的原因。
@淘宝褚霸
erlang 迄今为止这篇文章最准确的描述了erlang的调度原理以及如go,pthon等协程的差别，很有技术含量的文章。 参见：http://www.dikutal.dk/blog/jlouis/how-erlang-does-scheduling

几项RabbitMQ的设计指标参考：1、queue的数量与RAM大小相关，每个Q有一个process，idle时~10kb，活跃时~20-30kb；2、处理中的消息数不受RAM的限制，因为可能会换页到硬盘；3、同时连接的connection是主要限制，跟机器的TCP连接数限制相关，同时每个连接大约会消耗~66K内存，且创建~8个processes。
1000万个不会同时活跃的queue需要的内存为：10,000,000x10k约100G，给每个用户分配一个Q还是可能的。如果有计划地控制和规划同时连接的用户数，一台256G内存的机器应该可以支持1000万注册用户的订阅和推送。
回复@kong_hui:设计时大块消息不会用MQ传，这个选项只作参考。况且，消息体量一大，网络带宽可能先成瓶颈了。 //@kong_hui:关于第二点，考虑程序运行稳定，一般线上不建议打开swap

如果每个用户已经作为actor常住内存，且合理设计的话，每个用户的Q实际上可以直接用actor本身的Q，这样的话，公共的MQ只需用来处理跨机器的消息和公共消息。所以重点不如放到如何实现上述actor的Q和公共MQ的协作，尤其是最大化应用actor的Q。
如果用户分布在不同主机呢? 用户间如有通讯,主机内用actor,主机间用MQ??
我是在考虑这种方案，不过，也会考虑akka中直接支持的remote actor，需要再好好想想。
你设计的actor会自带节点信息嘛?就是传消息时知道对方actor的位置吗? 还是说通过路由来得到对方位置?
:需要设计额外的机制，考虑中。

回复@搭乘蒲公英的蜗牛:我是在考虑这种方案，不过，也会考虑akka中直接支持的remote actor，需要再好好想想。 //@搭乘蒲公英的蜗牛:如果用户分布在不同主机呢? 用户间如有通讯,主机内用actor,主机间用MQ??

选用remote actor还是MQ，需要考虑的主要就是消息传递可靠性和消息大小吗？
是在考虑在一定的成本约束下怎样设计最合理的架构，MQ的好处是有许多现存的功能可以不用再去额外考虑，而且我比较懒，不喜欢考虑太多特例，或者说愿意用一定成本换取简单和一致性，长远看其实省成本。

另一个方案是重型MQ，但actor只在用户连线时才激活(创建或恢复)，也即轻量的on-line actors。其实如果成本合适，两边都是重型的最理想。

回复@连城404:是在考虑在一定的成本约束下怎样设计最合理的架构，MQ的好处是有许多现存的功能可以不用再去额外考虑，而且我比较懒，不喜欢考虑太多特例，或者说愿意用一定成本换取简单和一致性，长远看其实省成本。
@邓草原
如果每个用户已经作为actor常住内存，且合理设计的话，每个用户的Q实际上可以直接用actor本身的Q，这样的话，公共的MQ只需用来处理跨机器的消息和公共消息。所以重点不如放到如何实现上述actor的Q和公共MQ的协作，尤其是最大化应用actor的Q。

按照每个用户的标识及分配规则将用户actor平均分配到n个node后，访问任何一个actor就可以通过akka的Lookup机制实现，比如context.actorSelection("akka.tcp://actorSysName@host_n:2552/user/actorName")，这里host_n是可以通过用户标识和分配规则直接计算出来，从而实现分布式环境下actors的互访。
如此，直接使用akka actor的message queue就可以顺便实现一套消息机制。公共MQ的任务就可以简单多了。
当然，需要考虑是让已经建立联系的actors保持长连接呢？还是每次重新lookup并重连。但总可以找到一个方案来平衡资源和效率的。
我让actors都保持in-memory，当然不止是为了通过MQ实现订阅和推送， 它会有很多有意思的应用和大大解放我们的思路

我还要想一段时间，等考虑得比较周全再说。前一个项目是上百万in-memory的重型actors+消息体量甚巨的MQ，已经证明了Scala下的actor是可以胜任这些任务的，这次的需求有所不同，正好可以进一步思考和扩展actor模式的应用场景。

回复@goroutine:这个依附于需求，我会界定actor的队列和公共MQ各自适合的任务。由于都是消息在流转，不管是在actor<->actor，还是actor<->MQ<->World，或者是actor<-MQ->actor，都是一致的机制，会大大简化设计。
@邓草原
按照每个用户的标识及分配规则将用户actor平均分配到n个node后，访问任何一个actor就可以通过akka的Lookup机制实现，比如context.actorSelection("akka.tcp://actorSysName@host_n:2552/user/actorName")，这里host_n是可以通过用户标识和分配规则直接计算出来，从而实现分布式环境下actors的互访。

scala的actor是调度到自动维护大小的线程池上运行，如果一个actor被一项长时间运行的任务阻塞，它所绑定到的线程也就被阻塞，如果同时发生这种情况的actors很多，那么被阻塞的线程也同样很多，因此同样需要考虑continuation和包装成消息驱动的nio等解决方案。实际上，物理极限不是actor要解决的(待续)
(续) actor的目的是基于异步消息驱动来归一和简化并行问题，重要的是提供了一种并行场景下更自然的思考方式。(完)

一台1T内存，4路共16核(4x4)Intel CPU的服务器现在价格在20万左右，如果是4路32核(4x8)则在35万左右。这样内存的机器，可以容纳约20亿akka的actors，actor的创建速度应该在每秒10万的量级，创建1亿个约1000秒(16分钟)，20亿个约5.5小时。如多核并行创建，即先从system创建比如32个parents，更快。
32核的机器一秒能调度多少个actor？要那么多actor有什么用，根本调度不过来。
你试过就知道了，完全能调度过来，实际上我设计的上一个系统上百万actors，很忙(计算量很重、消息量也很大)，CPU很闲。
等待传说中的JVM 多租户模型出来，或许又有了新的天地。进程作为隔离单元，少许有些重了，而完全的共享内存模型，不能够实现”进程“完全的隔离，适应面也受限。Java要往云计算发展，多租户模型或者类似模型一定会出来的。
设计得当当然可以管理得了，养成写class时想生存周期的习惯，该丢的丢，该长命百岁的长命百岁，该迁移到另一台JVM的就迁移。BTW，在128G内存的机器上实际应用没有遇到过问题。//@空谷松籁: jvm 根本就管理不了这么大的内存堆. >50G,暂停就够蛋疼的了. //@jebtang:转发微博
单JVM，那时只买得起这个配置。内面跑上百万actor，接收处理高频消息。 //@我是来测试的:128G内存, 是单JVM吗? 求具体情况.
还有一个方案是64台16G内存+2核的Mac mini，合计1T内存+128核，总价在6000x64=38.4万左右；如果能配每条16G的内存且价格合适，则可以用32台32G内存+2核的mini，合计1T内存+64核，总价或者可以控制在20万左右。用Raspberry Pi组合也不是不行，就是需要的机房空间可能更大。

如果actor的状态在初始化后*完全*由消息驱动，维护一个 actor的副本就很容易了，这时replicate要做的就是把发给actor的消息按顺序也发给副本。
这是出于HA的考虑么？这样还要考虑actor的位置？
是为了HA，考虑还是加套寻址的机构，实际上把所有节点管起来已经要引入Master之类

想把时间和空间同时在平面图上表现出来，始终是个难题。
如果对象的相对位置不重要，也许可以试试时空图？Lamport在Time, clocks, and the ordering of events in a distributed system里用的那种
是在画一些示意图、设计图，同时表现时间和空间。

考虑分布式的消息传递机制时，突然意识到除了MapReduce，还有UniteMap。

akka带mailbox的actor和几种dispatchers（http://doc.akka.io/docs/akka/snapshot/scala/dispatchers.html）应该可以很方便地用来实现一整套定制的MQ，不过还需要支持各种语言和平台的接口API。或者可以直接用zeromq来做这层接口，因为它已经有整套的接口API，这时可以把zeromq看作这套MQ的wrapper。
eromq有40+种语言和各种操作系统的接口，不但是MQ，而且可以是各种需要远程访问的应用的理想的wrapper。你需要做的仅仅是：选择或者定义一种传输协议。
:确切地说，0MQ有inmemory的Queqe，但本身没有Durable的Queqe，你可以自己实现它。
zmq 没有queue[哈哈]

自akka-2.2.0开始，spray取代netty用来实现akka的http和io，原因是netty的Java风格的代码(有太多的mutable变量)，而spray则是完全按Scala风格重新编写的RESTful实现。Akka和spray团队合作近1年后，双方决定将spray完全合并到akka。我正考虑用akka实现一套分布式的MQ，正好可以测试一下基于spray的IO。

这是合并事项的FAQ：http://downloads.typesafe.com/website/general/Spray-FAQ.pdf；这是另一个我感兴趣的模块akka.io：http://doc.akka.io/docs/akka/2.2.1/scala/io.html及http://doc.akka.io/docs/akka/2.2.1/dev/io-layer.html。

OO编程象搭积木，你可以搭出一只老鼠或大象，不过搭得不好就很容易折胳膊断腿，出了问题就头痛医头脚痛医脚；FP编程则象接管道，原料(数据)装进去就顺着管道流，然后在不同的出口就冒出来猫啊狗，出了问题不在猫狗身上改，而是去查管道(函数)，通则不痛痛则不通。

Actor根本上改变了对对象实例的看法。之前，实例就象个物件，需要时创建一个然后就不太管它了(反正有GC)。而现在，作为actor，它们不停通过消息相互或与外界交互作用，你突然觉得它们主动生动起来。要么倾向于让它们常驻内存(actor)， 要么用完即弃(消息) ，我明白这几年写的程序为何没多少GC烦恼了。

十五年前的故事：http://lists.squeakfoundation.org/pipermail/squeak-dev/1998-October/017019.html //@连城404: Alan Kay自己也称当年提的OOP跟actor更为接近。当年无法做到单机调度众多actor，几经转手之后原本理论上很严谨的actor model被各种工程妥协折磨成了C++、Java的OOP惨样。 //@邓草原:回复@灵感之源:是的，actor就是最初意义上、最准确意义上的对象。

回复@灵感之源:是的，actor就是最初意义上、最准确意义上的对象。 //@灵感之源:订阅消息，消息必然依附于某对象，那还是oo啊

第一个项目终于接近完成，顺便实现成了一个下一步彻底解决并发状态下对帐的事务问题的系统。系统具备实时对帐能力，基于akka，目前的actors数是数百万级，大约4G内存，主要是actor的状态占的字节（还可以优化）。得宜于Scala和akka，代码还是挺简洁的。

Akka的actor层次体系很有意思，我突然想到，不用n台机器，也不用n个JVM，在一个JVM里就可以模拟n个节点的行为。

SQL时代数据库承担几乎所有的数据组合、过滤等功能。而NoSQL能够兴起与分布式的大内存容量有密切的关系。在我看来，NoSQL要成功有几个关键：1、所谓数据表之间的联系弱化到主键，这样可以把表分布到各处；2、查找数据的线索都已经在内存或者缓存中。	
只是线索啊，你怎么做多字段模糊查询？
说线索是保守地说。实际上大部分经常用到的数据都在内存里，由业务针对这些数据处理各种查询，直接得到结果或者进一步查询的线索，必要时再去访问存储。
那得看数据结构了，如果几十万个账号，模糊搜关键字，单机内存没问题，但如果是微信新浪等量级，那要分布式了
Right，所以我在提到大内存时，特意在前面加了“分布式的”。

转推：New series on 'Running a 2400 Akka Nodes Cluster on Google Compute Engine https://www.typesafe.com/blog/running-a-2400-akka-nodes-cluster-on-google-compute-engine

我的理解，并发：同一件事有很多人同时都做，但各顾各的，各要各的。并行：把一件事情分给几个人做，各做一部分，结果是合集。//@灵感之源: concurrent并发，parallel并行...
@韦恩卑鄙
concurrent 和 parallel 搞不清楚真的是因为我们英文不够好。

前天跟@连城404 聊，他也问actor的消息传递是否是对强类型的削弱。在几年actor编程中我并没有觉得有什么问题。回来后又仔细想了想，对Scala而言，actor和消息本身都是强类型的，而actor的消息传递可以看作与外部世界的接口，这个接口或者channel与行为相关，即actor只会对特定的消息作出对应的反应...

(续)，或者说，actor的行为还是与强类型的消息保持一致，只是编译器不能保证目标actor一定会接收某种类型并作出相应反应。我觉得这反倒是在强类型语言中引入了一种类似动态类型的灵活性，只是这种灵活性被限制在actor通信的特定场景，或者说：一个内部强类型一致性的系统+与外部灵活开放的接口.

我是在想，对于我这种动不动就做大型重构的人，actor的“削弱”了强类型的消息接口为什么不是问题。//@GeniusVczh: 这不就是C#的await传播异常嘛……//@邓草原: 关于这个问题，我还会继续想...

连城404：这两天也在考虑这个问题，有一些想法，正打算给您发封邮件探讨一下。仅就重构这个问题而言，首先在不考虑channel的前期下，actor削弱了接口的强类型特征，使得IDE辅助的全自动重构变得不可能，那么重构时只能是人工遍历所有消息收发的位置。其次，您项目中的消息接口都在统一位置存放，便于查找...

那天聊天我用了人与人之间的协作做比喻，人其实是能分辨出在不同的场景下只对哪些消息作出响应，也许这个场景就是一种隐含的类型约束。//@邓草原: 我是在想，对于我这种动不动就做大型重构的人，actor的“削弱”了强类型的消息接口为什么不是问题。//@GeniusVczh: 这不就是C#的await传播异常嘛…

GeniusVczh：因为你对service的实现有confidence，想想你做错误恢复的时候就知道了//@邓草原: 那天聊天我用了人与人之间的协作做比喻，人其实是能分辨出在不同的场景下只对哪些消息作出响应，也许这个场景就是一种隐含的类型约束。//

连城404：前天您举完这个例子，我说一个actor收到了不应处理的消息，那么多半是系统中出现错误的信号，一旦发现应该立即追查和极力避免的。后来考虑了一下，一方面当系统的规模大到一定程度、工程师数量多到一定程度、单兵能力不再能够把控相应的复杂性时，您所说的“隐含”的类型约束就难以保证全局一致的；...

连城404：（续）另一方面，Akka这一系统的实现方式决定了它与Scala语言紧耦合，至少不会出现多语言混用的复杂情况，而且Akka基本思想继承自Erlang/OTP，子系统之间呈树状层次结构，且子系统间的接口相对较小，工程师即便无法掌握完整系统的复杂性，仍能掌握自己负责的子系统及其与相关子系统的接口的能力...

连城404：（续）只要不同时进行大跨度的同时涉及多个子系统的霰弹式重构，仍然足以保障“隐含”的类型约束全局一致。我想这也是Erlang虽然是动态类型，但爱立信仍然能用它写出百万行代码规模的AXD301交换机的原因。

灵魂机器：人在不同的场景下只响应某种类型的消息，这种时候AKKA的Typed Channels(也是您以前在微博上告诉我的)可以派上用场了啊~~~

邓草原：回复@灵魂机器:实际上我现在感觉Typed Channel引入了太多的约束，成为一种被迫参加的框架。

有一点@连城404 说得很对，就是nodes, actors本身通常会采取树状来分层和管理，如果设计时把这些考虑在内，也即把消息的流向也按照此分层，从而控制在一定的区域内，那么能够互相通达的消息流向也将遵循这个树状，这样围绕每种功能都会是这个树的一个小的分支。这实际上是actor模式很自然的设计。

白河愁：这种树状是很关键的，2.0版本更加强调了树状结构和管理。我发现我在1.0版本中acotr的设计很随意，升级了2.0以后，actor设计自然而然的演变成你说的那样子

白河愁：这种树状是很关键的，2.0版本更加强调了树状结构和管理。我发现我在1.0版本中acotr的设计很随意，升级了2.0以后，actor设计自然而然的演变成你说的那样子

灵魂机器：我觉得本质上跟人脑的习惯有关，咱们整理知识的时候，线形，星形，有向图，树型等，树型是人脑最自然的建模方法

(续) 这样一来，actor模式还自然导向了树状分层和中心、次中心化的架构设计，设计者会更仔细地按照消息流向来设计和组织子系统，在子系统内耦合紧密，但子系统之间的关联则应集中在很少的channels（开channel的代价也迫使他这么做）。这样的系统自然也是与分布式相符的，与现实世界也很相符。
@邓草原
有一点@连城404 说得很对，就是nodes, actors本身通常会采取树状来分层和管理，如果设计时把这些考虑在内，也即把消息的流向也按照此分层，从而控制在一定的区域内，那么能够互相通达的消息流向也将遵循这个树状，这样围绕每种功能都会是这个树的一个小的分支。这实际上是actor模式很自然的设计。

实体（及关系）、状态、消息，状态快照、消息流向... 程序设计越来越回归到围绕数据并将数据考虑为状态和消息。不知道有多少人真正看明白了SICP（计算机程序的构造和解释），尤其里面关于时间的段落。

好吧，socket.io没有akka下的版本，这块真的很重要，只好又自己动手了，直接绑定到akka.io和akka.http(spray.http)上去。

函数名相同但函数签名不同，所以就是不同函数。编译器会把输入输出参数及其类型（如果有的话）组合成函数签名加以区分，比如Java里public void main(java.lang.String...)方法的签名是：([Ljava/lang/String;)V //@老赵: 函数重载其实就是不同函数呗。
@ShiningRay
语言里面的函数重载是怎么实现的

对了overload重载是不是应该念ZhongZai //@邓草原: 函数名相同但函数签名不同，所以就是不同函数。编译器会把输入输出参数及其类型（如果有的话）组合成函数签名加以区分，比如Java里 ([Ljava/lang/String;)V //@老赵: 函数重载其实就是不同函数呗。
@ShiningRay
语言里面的函数重载是怎么实现的

签名中输出参数不重要，因为编译器决断时判断完名称+输入参数后不能再继续区分。//@邓草原: 函数名相同但函数签名不同，所以就是不同函数。编译器会把输入输出参数及其类型（如果有的话）组合成函数签名加以区分，比如... //@老赵: 函数重载其实就是不同函数呗。
@ShiningRay
语言里面的函数重载是怎么实现的

是可以做到，但实现起来比较复杂了，需要编译器分析调用时的场景。哪种语言是这么做的呢？//@老赵: 输出做不做区分是看语言选择的，当然也能做区分了。 //@邓草原:签名中输出参数不重要，因为编译器决断时判断完名称+输入参数后不能再继续区分。
@ShiningRay
语言里面的函数重载是怎么实现的

Scala中的隐式转换倒是需要对调用场景做分析，但也没有对函数的输出类型做区分。//@邓草原: 是可以做到，但实现起来比较复杂了，需要编译器分析调用时的场景。哪种语言是这么做的呢？//@老赵: 输出做不做区分是看语言选择的，当然也能做区分了。 //@邓草原:签名中输出参数不重要，因为...
@ShiningRay
语言里面的函数重载是怎么实现的

对这个话题感兴趣是因为spray中的所谓magnet模式：http://spray.io/blog/2012-12-13-the-magnet-pattern/ //@老赵: 是的，Scala是没做，能不能做是另一回事情 //@邓草原: Scala中的隐式转换倒是需要对调用场景做分析，但也没有对函数的输出类型做区分。//@邓草原: 是可以做到，但实现起来比较复杂了，需要编译器分析调用时的场景...
@ShiningRay
语言里面的函数重载是怎么实现的

Akka的actor层次体系很有意思，我突然想到，不用n台机器，也不用n个JVM，在一个JVM里就可以模拟n个节点的行为。

不少程序员有函数名重度强迫症，尤其是设计API的，因为他们总是试图抽象出能对世界作出“完美”概括的最基本的概念。//@邓草原: 对这个话题感兴趣是因为spray中的所谓magnet模式： http://spray.io/blog/2012-12-13-the-magnet-pattern/ //@老赵: 是的，Scala是没做，能不能做是另一回事情...
@ShiningRay
语言里面的函数重载是怎么实现的

搞不请她是问overload还是override，这就是为什么我觉得overload和override的中文翻译有问题。 //@GeniusVczh:@ShiningRay 在群里问我的是multiple dispatch啊……C++的这种重载，不就是挨个试一下然后决定吗。
@ShiningRay
语言里面的函数重载是怎么实现的

那函数重(Zhong)载就更是overload啦。唉，过载了。//@GeniusVczh: 约定俗成地，override一般叫重写，因为实际上也是重写//@邓草原: 搞不请她是问overload还是override，这就是为什么我觉得overload和override的中文翻译有问题。 //@GeniusVczh:@ShiningRay 在群里问我的是multiple dispatch啊…
@ShiningRay
语言里面的函数重载是怎么实现的

overload可以叫"再载"，override还叫"重载"。//@GeniusVczh:约定俗成地，override一般叫重写，因为实际上也是重写//@邓草原: 搞不请她是问overload还是override，这就是为什么我觉得overload和override的中文翻译有问题。
@ShiningRay
语言里面的函数重载是怎么实现的

Akka Persistence支持将actor的状态持久化到存储，persistence除了能帮助实现recover，还可以支持消息at-least-once确保送达。目前缺省的存储方式是LevelDB，可以通过扩展Storage plugin来支持其它的存储方式，比如正在开发的HDFS（我最期望的）

经过几天的技术准备(读文档、熟悉spray的代码和风格、改进sbt项目的IDE支持)，开始动手写akka上的socket.io。为akka和spray添砖加瓦呗。

就像Haskell是为了把世界上的99.999%的人都清除掉一样，monad是为了把剩下的0.001%的人再清除掉99%。总之，世界应该不需要人的思考就自己能运行，每引入一点人的因素，就被迫在Haskell的世界中想出新的办法来清除。
@GeniusVczh
【如何解释 Haskell 中的单子？】@flyfish1830：Monad是一种数学结构，haskell中的Monad意义和数学上的意义是一样的。简单的说单子(Monad)就是自函子范畴上的一个幺半群。这个幺半群的态射是作用在自函子上的自然变换，其单位… Oparker liu: 如何解释 Haskell 中的单子？ - http://www.zhihu.com/question/22291305/answer/21333050?utm_source=weibo&utm_medium=weibo_share&utm_content=share_answer&utm_campaign=share_button

看能不能找个时间写点我对monad的理解吧。//@软件攻城狮: 草原懂Haskell和monad不？我一直觉得你无所不能啊 //@邓草原:就像Haskell是为了把世界上的99.999%的人都清除掉一样，monad是为了把剩下的0.001%的人再清除掉99%。总之，世界应该不需要人的思考就自己能运行，每引入一点人的因素...

单从monad是这样那样，能这样那样，去理解monad，确实像盲人摸象，很难把握它。可如果你跳出来，想像什么样的东西能够作为最基本的单元来概括运算的本质，不管它是值的运算、还是类型的运算、不管是什么类型或者类型的类型，或者是运算的运算，可能能帮助你理解为什么monad会是这个样子。

而monad就是一个通用的combinator interface。//@GeniusVczh: 这个东西就是combinator
@邓草原
一种东西变换之后还是自己，但又不会完全是自己，因为需要能引入新的能力。同时它们串起来能处理所有问题，而问题本身又可以表达为自己，同时可以串起来被处理。

要实现这种变换，可以先从虚空中想像出一种context，不管里面怎么变，出来还是这个它。最简单的就是“有(Just)”和“无(Nothing)”，都归类为Maybe，然后是List之类的集合，再往上，包括运算本身比如Functor，Applicative等，最后终于到了IO。//@邓草原: 而monad就是一个通用的combinator interface
@邓草原
一种东西变换之后还是自己，但又不会完全是自己，因为需要能引入新的能力。同时它们串起来能处理所有问题，而问题本身又可以表达为自己，同时可以串起来被处理。

实际上从函数运算的角度，不存在单纯的“值”，1应该是=>1，或者说，所谓的常量值也是函数，只是每次不管输入什么都输出同样的结果。这样世界就只有运算，值是没必要的，更没有状态。但这是神的视角，而一旦人开始思考时，由于不具备神的无限的能力，只能在每个瞬间试图去把握世界，就看到了值和状态..
...以及状态呈现时的context/stage/舞台。但人希望能像神一样去理解世界，就只好从这每个瞬间呈现的一切中去寻找变与不变的东西，当他们历尽艰辛找到“不变”的“变换”时就迫不及待地将之命名为定律。
...可是，找到的与时间t无关的定律如此之少，所以不妨稍微松弛些，把尽量少部分的context和时间t也包含进来，就能把握更多的规律。实际上，从人的角度和视野，也确实能构造出一系列严谨的逻辑体系，只是它们永远不可能是完备的，从而需要不同的逻辑体系来补充对世界的认知。
...我一再谈到t，t实际上就是程序中的所谓指令式代码，它们是顺序相关的，由时钟驱动一步一步执行的部分。时钟和顺序在这里是如此重要，以致一旦有并行的行为，就不得不考虑各种笨拙的同步手段。所以，只有消除了t的部分，才真是是属于神的东西，无所谓开始、无所谓终结。

websocket支持一直是spray社区呼声很高的功能，但spray team似乎在等play-framework team来解决(等play完全移植到spray后)，但我们不能再等了。待我一并实现socket.io支持后会与spray team联系，看他们是否接受我的提交。当然，我的实现必须遵循他们的设计思路。

spray服务架构： 1、创建一个listener(actor)来侦听端口；2、为每个访问客户端建立一个connection(actor)，3、connection actor的behavior转换(become)为piplelines(Receive类)，一条commandPL，一条eventPL；4、pipeline由若干stages通过>>方法连接而成；5、pipelines中，事件上传，命令下达。

比较了一下Netty的websocket parser代码，我的实现还是还是不错的，当然也得益于Scala。

继续socket.io，写了些解析packet的代码，不太满意，也许应该用parboiled试试Parsing expression grammars (PEGs)。(spray的json解析就是用的parboiled，性能一点不差)

有意思，akka准备放弃io中的pipelines架构(在2.2.0引入但一直标注为experimental)，转向受 RxJava启发的Reactive Streams。估计最近几周会陆续放出代码，并集成到2.4中。正在开发的spray-websocket和socket.io不会受到这些影响，但会持续跟进spray和akka的进展。
hongjiang_wang：今天看了一下邮件列表，2.2.x系列io是试验性质，pipeline架构的api太重且不直观。对RxJava之前没了解过，看了一下是netflix把.NET里的reactive extension移植到JVM上，比较符合typesafe提倡的“响应式编程”
邓草原：回复@白河愁:是异步处理，保存状态一般情况下并无问题。但切换时就可能要考虑切换一刻原先pipelines中的状态是否需要接过来。
白河愁：pipelines是同步处理的原因?

快速想了一下。本来我在spray-can中patch了一个标准的HTTP Upgrade命令，可以切换到自己定义的pipelines，也注意到由于pipelines中会保存状态，所以切换时还得小心。现在干脆在spray-can外单独复制几个类出来，不改spray-can了，先让HTTP和WebSocket作为一个单独的服务起来。
@邓草原
有意思，akka准备放弃io中的pipelines架构(在2.2.0引入但一直标注为experimental)，转向受 RxJava启发的Reactive Streams。估计最近几周会陆续放出代码，并集成到2.4中。正在开发的spray-websocket和socket.io不会受到这些影响，但会持续跟进spray和akka的进展。

除非它是一个actor。//@面吃太多:一般认为，如果它是不可变的，还单例它干啥？
@邓草原
Scala中如果你想把一个object作单例，最好保证它是无可变状态的。

spray-websocket的代码现已放到：github.com/wandoulabs/spray-websocket，有一个简单的例子在spray.can.websocket.test.SimpleServer.scala，可以用sbt run在8080端口跑起来。

跟@陈兴润 讨论时想到，应该找时间总结一下iterable, observable, sequences, pipeline, stream, queue这些概念的关系了。

对，Iteratee也应该加进来。也许这些概念还要加上和Future也做个对比才能看清更多。//@陈兴润: playframework 里的 Iteratee 也蛮有意思~
@邓草原
跟@陈兴润 讨论时想到，应该找时间总结一下iterable, observable, sequences, pipeline, stream, queue这些概念的关系了。
都说到这份儿了，那把continuation也说说吧，这些都是状态变换与流程控制的范畴。

akka //@王海鹏Seal: 求经典scala代码，反复揣摩。//@邓草原: 回复@令狐无忌哥哥:最好团队先有一个熟手，能随时或者集中解答疑惑。实在看不懂的代码可以先跳过。自己写则从易到难，不要先执着于写出特别的代码。
@邓草原
跟@陈兴润 讨论时想到，应该找时间总结一下iterable, observable, sequences, pipeline, stream, queue这些概念的关系了。

综合一下，Iterables, Observables, Sequences, Pipes, Conduits, Streams, Queues, Iteratee, Enumerators等，这些概念的关系需要理一理了，而且要加上sync, async的角度，与Future的关系等等。或者还需要碰一下Monad。有种感觉，Haskell的选手有大批用Scala来搞真的。

这些概念从OO的角度会发现不太好抽象归并(为什么)，Haskell对这类问题的抽象能力最好(为什么)。
@邓草原
综合一下，Iterables, Observables, Sequences, Pipes, Conduits, Streams, Queues, Iteratee, Enumerators等，这些概念的关系需要理一理了，而且要加上sync, async的角度，与Future的关系等等。或者还需要碰一下Monad。有种感觉，Haskell的选手有大批用Scala来搞真的。

从akka的演变方向可以看出，它放弃了一些看上去能带来actor使用便利的特性(比如只能通过ActorRef访问actor)，其目的已远不止是并行并发，而是指向了透明的分布式平台。
Akka文档上也说了是inspired by OTP。不过Akka更好地发挥了静态强类型的优势，表达力更强，代码更简洁。另外Akka actor的receive/become的编程模型更符合原始的actor model的定义（虽然未必算优点）。比起OTP最大的缺点还是无法保障调度层面的实时性，这点不动JVM应该搞不定。
好像开始转向reactive了

Netty5.0架构剖析和源码解读.pdf http://vdisk.weibo.com/s/C9LV9iVqH13rW

回复@kong_hui:我当然是nbscala: github.com/dcaoyuan/nbscala //@kong_hui:那您现在用的什么IDE？求推荐scala IDE
@陈兴润
是 Scala 的语法太复杂还是我的代码太诡异，IntelliJ 的 scala plugin 总是提示语法错，越升级问题越多，但编译却是正常的。。。

或者我现在就在spray-socketio中先试一下用Rx来对付incoming packets。

Rx让我想起了先前做的金融计算平台，当时用Actor异步实现了一系列的实时增量依赖并行计算，甚至一直联到了UI。整个系统完全由市场的实时状态和数据流自动驱动。

spray中event pipeline和command pipeline还是改成叫inbound/outbound pipeline好些

在spray-socketio中暂且引入了RxScala(RxJava的wrapper)，用来以事件(数据)流的方式驱动业务逻辑，代码看上去还行。还没有写让akka调度RxScala的代码，或许会等akka决定采用哪个Rx实现。

akka actor的Stash trait可用于暂停处理接受到的某类消息并将这些消息暂存起来，直到你调用unstashAll()，便可继续按原来的顺序处理暂存的消息。这对于实现socket.io中客户端中断后重连非常方便。与push方式的Rx消息流配合起来好像可以很强大。#哪天我真的会用akka实现一套MQ吗#

akka是基于“事件/消息/数据”驱动的，但怎么表达“事件/消息/数据 _流_”呢？Rx就是一个选项。//@septem_: 有一点不明，请教一下，akka是事件驱动的，本身就能实现reactive的应用，为何还需要引入另一个rx框架呢？
@邓草原
在spray-socketio中暂且引入了RxScala(RxJava的wrapper)，用来以事件(数据)流的方式驱动业务逻辑，代码看上去还行。还没有写让akka调度RxScala的代码，或许会等akka决定采用哪个Rx实现。

回复@bigbully_:是这样，但还是有代价。比如mutable内部数据结构可能更连续和紧凑，而且也通常会预分配空间。 //@bigbully_:不是说immutable集合在+=的时候虽然会不停的创建新的集合，但效率不会很低，因为老的集合和新的集合共享大部分结构吗
@bigbully_
scala什么时候应该用mutable的map或set,看到kafka源码里发现用的基本都是mutable集合，即便集合里只放一些String @邓草原 @hongjiang_wang

Building Reactive Applications with Akka by Jonas Bonér, Mar 20, SF Scala. "In this talk we will introduce you to Akka and discuss how it can help you deliver on the four key traits of Reactive; Event-Driven, Scalable, Resilient and Responsive" and hiring.  http://www.meetup.com/SF-Scala/events/166180622/

spray-websocket现在终于通过了所有autobahn的测试用例，包括ssl下。
@邓草原
跟@陈兴润 花了两天终于从spray的SslTlsSupport stage的一个坑中跳出来。原本的实现主要针对request/response一来一往的情况，但不能处理WebSocket等可以连续发送frames的协议。主要症结在于它处理inbound/outbound数据时会进入连续递归的状态，但出来时却认为只有一次发送，并只考虑一次ACK(内部的)。

“大部分游戏世界里的数据都一直存在于内存中。当服务器启动后，一旦数据加载完毕，大部分不再需要退出内存。服务器只是在不断的创造新数据并让这些数据在内存中流通而已”。有意思的是，不仅在线游戏，近几年遇到的系统，不管是金融还是移动互联，我都倾向于这个模式，而同时它们是如此地接近actor。
@简悦云风
本来想写篇总结的，结果一开头就发现这是个长篇，晚饭前是写不完了。看起来要连载了 :) http://blog.codingnow.com/2014/03/mmzb_db.html 谈谈陌陌争霸在数据库方面踩过的坑(前篇)
邓草原：回复@shell0dh:有多种方式。比如我以前的微博谈到过，数据（状态）可分为演变中和已经固化的，演变中的状态需要实时的备份服务和同步，包括以快照等方式定期持久化，固化的状态简单持久化。系统完全崩溃后，1、装载固化的状态，2、重演尚未固化的状态直到现在。
shell0dh：怎么保持高可用呢？内存毕竟还有丢失的可能，只加载原始数据，后续增量数据都从新计算？

spray-websocket: 毕竟是很正式的项目，所以对带hack性质的代码总是要回头修订。但这一点都不好玩。一般来说，就是把能跑的代码改到不能跑，然后让自己接近崩溃的过程。半小时前我几乎要崩溃了，然后就发现了问题所在，然后就又半小时过去了，改好了。睡觉。

静态类型对于重构是如此的重要。有时，我只需要先想象一下这个地方应该改成，给一个什么类型，然后拿到什么类型。草写一下，然后编译，然后就可以按照编译器的提示一口气改好。

在用spray-websocket的client写个简单的性能测试工具，准备初测一下spray-websocket和spray-socketio的server. 算是自己测自己。
https://github.com/wandoulabs/spray-websocket
https://github.com/wandoulabs/spray-socketio

spray-socketio.。草写了个测试程序，自己测自己。在我的笔记本上初测，client和server分别占到1.5G和2G内存时开到5000个连接。当每批消息数发到12万时开始丢信息，这时平均响应时间为1.3秒。开2000个连接时，可以抗到每批消息20万，平均响应时间3秒。总之，8万/s的响应无压力，且性能与消息量呈线性。

一般来说，akka的一个actor每秒转发100万消息没有问题，测试的结果看，20万消息100多毫秒本地发完。测试的一个设定是所有消息必须在5秒内一个不少地返回，否则就停机。目前程序到系统都未作任何优化，这是下一步的任务。明天，不，今天，用两台独立的机器再测一测。
@邓草原
spray-socketio.。草写了个测试程序，自己测自己。在我的笔记本上初测，client和server分别占到1.5G和2G内存时开到5000个连接。当每批消息数发到12万时开始丢信息，这时平均响应时间为1.3秒。开2000个连接时，可以抗到每批消息20万，平均响应时间3秒。总之，8万/s的响应无压力，且性能与消息量呈线性。

其实我原本担心的是比较匆忙的实现和引入了RxJava后对性能会不会有没想到的影响。从初测结果看，可以放心。在一台几十G的普通服务器上，不需很仔细的调优保持50万的长连接应该可以达到，每秒处理20万以上的socket.io消息也应该可以达到。

测试代码已经提交到github，在spray.contrib.socketio.example.beanchmark目录下，用sbt的run可以看到SocketIOTestServer和SocketIOLoadTester运行类，分别运行就可以（代码现在还比较简陋）。akka用来写load test也是很好的选择。

spray-socketio. 写了个sbt dist命令和几个脚本，方便脱离sbt直接跑测试。还是在我的笔记本上同时跑client和server。开到2万个长连接，server占用内存2G。响应时间稳定在1s时，可处理9万消息。当5秒内全部消息不能返回时停机，这时100ms左右发了23万消息，平均响应时间为2.8s，server内存占用为2.7G。

要大改一下spray-socketio。为了分布式，需要想办法消去那些被一批actors所依赖的actor（内面通常保存着一些查询表）。

spray-socketio: 我的笔记本上跑到了5万长连接（同时跑C/S），性能仍能保持在9万消息/秒，并在20万消息/秒时才遇到5秒超时，这时服务器内存在2.7G左右。

spray-socketio: 很高兴@陈兴润 把高可用分片集群的代码也调通了，spray-socketio可能成为地球上最强悍的socket.io实现，当然，spray-websocket的集群就更没难度了。
邓草原：回复@小稻640:是的。Akka-2.3.0开始支持persistence和sharding.
小稻640：高可用分片集群也是针对 Akka 的方案么？

回复@刘江总编:注意到了。体现了即使在高并发和大数据的场景下，数据要是"活的(Active)"和做出即时反应的大趋势。不过它对Akka的看法并不全面和及时，因为在Akka平台的近期实现中，actor已经具备Orleans所提及的“actor always exists, virtually”的能力，由此其高可用性的粒度已经到了actor级别。
@刘江总编
Orleans项目：微软在.NET上实现了类似Erlang的Actor模型，并更进一步，通过一个虚拟化层使Actor的管理自动化和透明化，大大简化了大规模分布式并发应用的开发。O网页链接 Halo 4基于Azure 每秒几十万次请求，涉及几千台服务器的实时服务就是用Orleans开发的。

在豌豆荚的基于Akka的spray-socketio分片集群的实现中，就是"actor always exists, virtually"，尤其是带状态的actor，或者直接叫entity actor可以很简单地实现分片集群和active/reactive on demand，并且以EventSource的形式更新和保持状态(包括持久化和基于Event重演的状态恢复)。

续）这种高可用粒度到actor级别和active/reactive on demand的策略使得所谓的standby的“热备”节点可能不再是必须的，从而可以节省差不多一半的设备和维护投入，并简化了高可用的实现。我正考虑找时间做一次分享。

喜欢布道的Martin Fowler正在准备推出他对Event Sourcing的思考，也即他所谓的“Capture all changes to an application state as a sequence of events”。这在Akka的集群和持久化机制中是一个现实的实现，也很类似我以前在完成金融计算平台时的设计。Akka也准备实现一套分布式的Reactive Streaming..
orthogonality：Event Sourcing的想法很好，把OO的对象状态变化问题转化为了事件流处理问题，属于函数式思想的很好应用。
寻找一个苹果：赞同，交易行为(状态)的记录和分析，辅助以内存数据库和流式分析，DDD描述的美好世界终于有了最接近的技术方案。这是对传统事务处理的解耦过程

续）最近看到很多围绕Reactive Streaming，Event Sourcing的说词，这反应了一种新的趋势，微软在Rx中对这个趋势做出了尝试，今天你会发现：event是stream，callback是stream，甚至entity也是stream的结果，而对stream(这里我把它定义为包括尚未发生的xx的流)的操作与对数据的SQL操作是可以微妙一比的。
邓草原：回复@shell0dh:可以看一下微软Linq对Rx和SQL的操作。google一下Reactive extension.

Akka的Event sourcing和persistence有简单明了的例子吗？Jonas Bonér写了两个：https://gist.github.com/jboner/9990472 ， https://gist.github.com/jboner/9990435

是想对数组做并行计算还是只要保证线程安全？这样的数组只有一个还是很多个？如果是后者，每个数组一个actor。
@老师木
一个数组，多个线程随机存取。或者给数组加个lock。或者每个线程都维持一个自己的拷贝，适当的时候reduce一下。好像在不同条件下，应该不同的选择。应该还要更有效的方法吧，譬如用好更新数组和每个线程计算之间的overlap

如果按行独立计算，且行数超过CPU核数，采用actor模式应可行。actor数基本无上限，每个actor也是线程安全的。//@老师木: 并行计算。数组是2维数组，每行一个actor很符合我的想象（要查actor是什么），假如行很多，actor有上限吗，每行一个锁，是不是锁也有上限。
@老师木
一个数组，多个线程随机存取。或者给数组加个lock。或者每个线程都维持一个自己的拷贝，适当的时候reduce一下。好像在不同条件下，应该不同的选择。应该还要更有效的方法吧，譬如用好更新数组和每个线程计算之间的overlap

Scala的Type system虽然不是迷宫，但还是给使用者带来一些困惑。要把这类问题想清楚其实是需要人去认真总结和注释的。这篇文章：“Scala’s Types of Types”就很棒。http://ktoso.github.io/scala-types-of-types

不过Scala更具严谨和一致性。难度方面，Martin已经在着手Dotty：https://github.com/lampepfl/dotty，类型系统和语法都更简，当然，照例是研究先行：http://www.cs.uwm.edu/~boyland/fool2012/papers/fool2012_submission_3.pdf //@GeniusVczh: scala的类型和符号的学习难度已经超过C++了……
@邓草原
Scala的Type system虽然不是迷宫，但还是给使用者带来一些困惑。要把这类问题想清楚其实是需要人去认真总结和注释的。这篇文章：“Scala’s Types of Types”就很棒。
有什么问题吗？任何语言中都有基本/原生类型，然后它们可以组合成新的类型或者不需要类型的List, Tuple, Map等。 //@darionyaphet:其实 我还是不是很明白为什么要把基本类型和引用类型的积累分成两个

选取自己能快速掌握的部分就已经能写出很好的Scala程序，其实比Java更易入门。//@李智勇SZ: Scala 不懂，但如果一门语言学习难度超过c++那基本上是躲远点好，不管有多少好处。//@文艺复兴记://@邓草原:不过Scala更具严谨和一致性... //@GeniusVczh: scala的类型和

我只能说未必有现存的能对应的啥，但是通过隐式装换应该能实现前者，而后者也应该能通过各种手段实现。如果可能的话请提供两个简单的例子我试试。//@GeniusVczh: 不知道Scala有没有F#的那种computation expression和type builder啥的，基本上这类东西才是吸引我去用的部分，反正大家都是强类型语言。

哦，刚想推荐scalaz，通过它可以看到Scala怎么稍有变态地实现变态的东西。//@GeniusVczh: 我来瞟几眼//@KimmyLeo: @GeniusVczh http://eed3si9n.com/learning-scalaz/Monad.html //@KimmyLeo: 有吧貌似，但是奇葩得很。//@GeniusVczh: 不知道Scala有没有F#的那种computation expression和type builder啥的，

回复@ice_wing:那就把Scala那部分改成总能吧。 //@ice_wing:未必能和能差不多是一个意思？ //@邓草原:用C++未必能写出比C更好的程序，但用Scala能更好地写出比Java更好的程序。

用spray-socketio实现大规模有状态长连接集群的技术难点基本都验证完毕，这是实时流式计算的入口。接下来呢？作为基础架构中的MQ，虽然有各种具分布式和高可用的实现，但离我设想的多少有距离。我在考虑要不要用akka来做一个。想了几天了，也写了些原型代码，估算了一下可能一个月出原型，两个月初成。

多好，21天学会scalaz。
@GeniusVczh
http://eed3si9n.com/learning-scalaz/index.html http://ktoso.github.io/scala-types-of-types/ 地球上第一个比C++更复杂的语言诞生了——Scala

在伦敦的The Reactive Programming Conference集中了一些高智商的家伙。包括Jon Armstrong大叔和Jonas Bonér。Jonas的演讲中有不少对未来分布式计算的展望，其中有一句是：In-place updates (as in DBs) need to die. Hard drives are no longer expensive. No excuse not to keep history. 很对。
续）当然还要加上另一个配合的条件，就是1000核的计算机已经很近了。总体而言，任一时点的状态是由一系列已经发生的事件决定的，这些_immutable_的事件是分布式处理的关键，而并行计算已经强大到可以从历史事件随时重演出任一实体的任一时刻的状态。
续）在几年前设计分布式并行金融计算平台时，我仔细考虑过这个问题。金融交易是典型的交易事件+快照的事件流，整个交易和策略完全可看作由事件流实时驱动的巨大的状态机，非常适合这样处理。现在在移动互联领域再次思考这些问题，其本质是一样的，甚至更典型。

下一代Raspberry Pi将分成内存和CPU的计算模块和IO模块两部分，但我在认真考虑MininowBoard的Max。$129配1.33G 64位双核Intel Atom和2G DDR3 RAM，也即8K毛币可获20核、20G内存和10个网卡及SATA2端口，计算和IO能力都够强大了，可以搭出100万+长连接的服务集群和分布式消息存贮系统。

第三方就是常常搞得调用不成功的一方。[嘻嘻]//@灵感之源: 最享受的一刻，是第三方调用成功的时候
@邓草原
基础软件的编写相当枯燥，除了跟各种文本和二进制协议打交道，就是大量时间在处理各种边边角角的场景。所幸有Scala让这一切变得稍有趣些。	

reactconf @toddlmontgomery: Share state by passing messages, not by exposing mutable shared state; A message is payload on wire, an event is what causes state transition; Events are fire and forget; Errors are just events; This changes way you view the world.

@headinthebox getter: () => A, setter: A => (); +ErrorHandling: () => Try[Option[A]], Try[Option[A]] => (); +Latency: () => Future[Try[Option[A]]], Try[Option[A]] => Future[Unit]. Observable,Enumerator: setters and getters with right signature, making all side effects explicit.

Palm的mochi界面（已开源）用来做blog的界面应该也不错。https://github.com/enyojs/mochi

Scala的优点，不需要增加关键字，不动声色就实现了某些东西。//@hongjiang_wang: 其中的新模块: scala-async 值得关注
@邓草原
"Welcome to Scala-2.11" - Slides by Jason Zaugg from Typesafe Scala compiler team. http://retronym.github.io/welcome-to-scala-211/

Typesafe宣布Akka Streams - Reactive Streams Initiative的一部分，同时包括一份Reactive Streams规范草案，等等。 https://www.typesafe.com/blog/typesafe-announces-akka-streams

Akka 2.4计划的任务要点有：1、Akka Stream； 2、Akka HTTP Layer，包括http client/server，以提供RESTFul服务，并让Actor可使用REST call；3、Remote transport从Netty替换成基于Akka Stream。以上变化使Akka朝着完全没有阻塞的分布式框架继续往前走。
shell0dh：我还没弄明白akka默认通讯框架是自己的呢。还是netty?
邓草原：回复@shell0dh:Remote actor通讯现基于Netty。但Akka I/O模块已经是直接在Java nio上。
shell0dh：回复@邓草原:Akka I/O为啥没直接为默认的Remote Actor实现呢。没netty性能好？
邓草原：回复@shell0dh:一点点来

Akka及其集群会在actor或者节点挂掉时自动恢复，但并不保证期间的消息不丢失。这是对的，因为这应该留给更上层的逻辑和协议去实现。这是为什么我开始考虑Akka上的AMQP。

有一种类型X，它的特点是与任何类型A“或”都是A，也即(X | A) is A。为满足这个判定，这个X必须是任何类型A的子类。现在就差给它，X，起个名字：1、不能叫“万物Any”，因为Any不是任何类型的子类，而是相反；2、不能叫“空Nul”l，因为Null还是Sth的一种形式；3、就叫“无Nothing”，它的反面正是Any
@时蝇喜箭
Scala中Nothing（类） is a subtype of every other type 。。。一无所有是有的子类，#好像有哪里不对# @邓草原
继续。类型是一些行为(接口)的集合，也即子类要具有父类所有的行为(接口)。Nothing是“无”，也即对任何类型，“无”都具备它的能力，只不过不是在“(现)实在”，而是在“虚”中，或在“后来”。实际上在抛出异常时就是Nothing，也即“它”可以在“后来”实现，“后来”可以是无限，但“总能”。
回复@westhood:对，这句概括得好。 //@westhood:Nothing is virtually everything 
而且，有什么可以是Everything呢？Nothing。
1 orElse Nothing: Int //@GeniusVczh:nothing也可以转成int吗？丧心病狂

Reactive Streams要实现回压(backpressure)流量控制，Publisher会有一个 signalAdditionalDemand(n: Int)之类的接口，让Consumer可以先告知Publisher接下来希望接收到的元素数，然后Publisher会异步一个个地push该数量的元素。我想了一下对网络数据流的实时parsing，这个比hasMore(len)更有用和好用。

何况不会只有一条流的。//@邓草原:回复@shell0dh:你永远可以找到分叉，合流的地方，也许每个分叉是强序的，那就顺序处理，多个分叉并行处理，合流处异步等待就绪Push，这时你可以干点别的。//@shell0dh:如果在一条强顺序流上是没办法做的并行对吧？还是说其实每个强顺序流最终还是能找到并行的点？

代码界经常被自己套用或发明的名词搞糊涂。现在去洗澡，顺便想想stream, pipeline, flow, iterator, iteratee, observable, subject, publisher, consumer, subscriber, subscription, queue, event, message, state, status... 究竟是怎么回事。我觉得要回归自然界了，自然界找不到的就是骗人的。

reactive-streams在github上围绕各种概念和设计争得有点热闹了，不过，也许大家慢慢能理解各自的语义，然后在这个基础上厘清各种场景，最后得出一个比较均衡的方案。比如这个：https://github.com/reactive-streams/reactive-streams-jvm/issues/19

假设一个人要迁移到遥远的仙女座星球，考虑到光速和其它限制，他只能以灵魂的方式将自己的N世因果的log先传递到那里，然后，他需要在那里找到一个重演自己log的方式，从而就地取材在彼处“重生”。最简单的方式就是投胎。

Akka分片集群中的Actor大体上可以说是集Java EE的entity bean, stateful session bean, message bean于一体，而是是异步的。

啊哈，@陈兴润 刚上了@akkateam 的Tweets。在akka最新的doc中专门加了一段描述这个4. DistributedPubSubMediator.Publish with sendOneMessageToEachGroup。

"The idea behind Akka Streams is to leverage the battle tested Akka Actors to provide a straightforward execution model for statically typed streams of data that consume system resources in a predictable way," Klang from Typesafe.

今天QCon上的演讲内容较多，但大体可概括为：1、不关心状态的长连接集群；2、带状态的分片集群；3、Reactive实时流式业务处理。贯穿其中的是：“数据/消息”流过“计算/处理”的Actor单元，改变或不关心Actor的状态，并输出新的“数据/消息”驱动下一个Actor单元。而Actor是并行和增量计算的最小单元。

QCon北京# 上的讲稿《Akka下的分片集群》

Oracle NoSql Database还是挺有意思的。BDB的KV Store+Avro的JSON schema+Avro的value存储格式。Table对应Avro的Record，Record的Fields是KV对。跟我想像中的理想的Not Only SQL存储完全一致。

杰才Paul Phillips似乎在用Scala写一套JVM spec。这是片段：https://gist.github.com/paulp/c8d50c508d1ecf51ae86

AvroPath完成了Select, Update, Delete, Insert等功能，这部分先到这。其实就是差不多有了一个查询/操作能力和伸缩性可能比Redis更强的分布式数据存储服务。
小稻640：想问下，AvroPath中每个Key-Value 是以单独 Actor 存在的么
邓草原：回复@小稻640:是

CEP using Akka Streams http://www.franklysauer.com/2014/05/cep-using-akka-streams

Evaluator可以输出“.books[0:1].title”之类的玩意了。好久不写这类东西，才找回感觉。 //@邓草原: Parser差不多了，测测后就该写Evaluator了。
@邓草原
要给Avro实现一套类似xpath和xquery的访问。Parser这次手工写呢还是继续用PEGs...

这类东西确实很有用，沿着graph找东西。本来可以用PEGs写，最终还是手动了。//@GeniusVczh: 之前我才刚给我的gacui写了一个类似的，用来指定一个style如何应用在UI上 //@邓草原: Evaluator可以输出“.books[0:1].title”之类的玩意了。好久不写这类东西，才找回感觉。
@邓草原
要给Avro实现一套类似xpath和xquery的访问。Parser这次手工写呢还是继续用PEGs...

其实用Akka Streams重写的spray http pipelines也初步有模样了，在这里：https://github.com/spray/akka/blob/53d4384/akka-http-core/src/main/scala/akka/http/server/HttpServerPipeline.scala#L35-62
@邓草原
CEP using Akka Streams http://www.franklysauer.com/2014/05/cep-using-akka-streams

基本完成。除了可以Query，还可以据此Update。跟手头的另一块结合就是很好的支持丰富查询表达的分布式缓存，如果用起来，可有效缓解几个项目的并发压力。而且，跟persistence结合，还可能成为不错的NoSQL分布式数据库。
@邓草原
要给Avro实现一套类似xpath和xquery的访问。Parser这次手工写呢还是继续用PEGs...

对于distributed actors，Akka认为在gossip这类p2p理念的协议基础上来协调状态比zookeeper等更合适，实际上他们尝试后认为zookeeper proved a poor match for distributed actors。这个问题有时间我得好好挖挖。不过，actors天然象一个一个p，所以从逻辑上来说我也倾向于在p2p的视角上去努力。

如果加上可快速替代或可恢复的资源呢？//@hacker101:现实中的p2p的资源节点天然具有资源的可替代性.节点的数据也不需要顺序获取, 只需要最后合并就 ok. akka 的计算节点就不一样, 肯定有 context 依赖.尤其是长连接服务.
@邓草原
对于distributed actors，Akka认为在gossip这类p2p理念的协议基础上来协调状态比zookeeper等更合适，实际上他们尝试后认为zookeeper proved a poor match for distributed actors。这个问题有时间我得好好挖挖。不过，actors天然象一个一个p，所以从逻辑上来说我也倾向于在p2p的视角上去努力。

看过几个部署、维护、监控小actor的小工具。感觉在撤销/部署新的actor上会有不错的方案出来。如果JVM的启动速度越来越快(甚至有类jvmdocker之类的)，与akka集群配合就基本敢用了。//@Erlang: 先有部署和维护工具再说微服务//@邓草原: micro services这个词总让我去想actors。
@陈兴润
这几天在qconfny听的几场讲座，出现频率较高的关键词叫micro services，概念很简单，就是把一个大的服务拆成很多小服务独自开发维护部署。实践起来需要较好的工具支持，尤其是自动部署，依赖管理等等。

Akka做了状态收敛时的leader，具体细节待探。//@DMT胖子:不太同意，zk依靠两阶段提交总能保证cluster在一个一致性状态，gossip可不能保证
@邓草原
对于distributed actors，Akka认为在gossip这类p2p理念的协议基础上来协调状态比zookeeper等更合适，实际上他们尝试后认为zookeeper proved a poor match for distributed actors。这个问题有时间我得好好挖挖。不过，actors天然象一个一个p，所以从逻辑上来说我也倾向于在p2p的视角上去努力。

说实话，我总觉得强一致性需求的Akka集群需要配一套类AMQP的MQ，这套MQ可以用Akka来实现，但它不应该是Akka本身(的)。
@邓草原
对于distributed actors，Akka认为在gossip这类p2p理念的协议基础上来协调状态比zookeeper等更合适，实际上他们尝试后认为zookeeper proved a poor match for distributed actors。这个问题有时间我得好好挖挖。不过，actors天然象一个一个p，所以从逻辑上来说我也倾向于在p2p的视角上去努力。

Akka集群支持在同一组nodes上（叫akka.contrib.cluster.sharding.rule）部署多种actors的分片（可惜目前不支持指定不同组的nodes上分别部署不同的Actors）。因此在开发角度可以做到业务不会侵入基础架构的集群（但基于前述理由，运行时会）。#有时间改吧#

Akka集群正一步步成为潜力巨大的极具通用性的集群不是偶然的。在业务上它把各种要素统一为消息和Actor，在逻辑上统一了并行和分布的计算范式，它还是类型安全的。与JavaEE不同，它也不需要重度的容器。我想不出来还有哪个平台达到了这样的程度。

playframework 3.0: reactive streams replacing iteratees, DI by default, Java-Scala API consolidation, no global state, akka-http backend (via @pk11) 。spray-http正在成为akka-http的一部分，playframework则将与akka-http和akka-streams合流。我所在的team将追逐这一潮流。

很棒的幻片（akka-http和akka-streams）：http://spray.io/scaladays2014/

2014的slides刚出来了:https://www.typesafe.com/blog/scala-days-presentation-roundup

回复@shell0dh:如果你常来，就会一直有一个跟你对应的、专属与你的actor。 //@shell0dh:回复@邓草原:估计我的请求。走过路过不少Actor哈哈。。
@邓草原
今天akka小集群来自外部的请求数大约会到全天4亿次，这个数不算高，但比预估的大... 集群开始逐渐进入到真正的压力区。

Scala REPL要支持的一个基本功能是哪怕输入一两条简单的代码/片段也要可以执行，所以要包在一个类的main方法中。对Scala来说，把这些代码放到一个Object中是最简单的。不过改为将代码放到一个Class中，然后从外部去new和执行确实更合适些。
@徽沪一郎
Apache Spark源码走读之16 -- Spark Repl实现详解 Spark为什么不直接使用scala提供的repl而非要自己另搞一个repl呢，其后原因为何，谜底尽在本文。 http://www.cnblogs.com/hseagle/p/3810486.html 初涉scala编译器实现，心虚啊。

今天遇到一个诡异的Akka分片集群领节点自杀的状况。#我们踏坑而来#

分布式计算将大量计算机组成一个团队（集群）一起做事，需要leader、需要分工、需要沟通、需要及时了解各自的状态... 无论如何，计算机组团工作让我想到越来越多的人的行为特征。

这些天，akka集群的各种节点被我用不同的方式杀掉、复活、折腾，还算是能跌跌撞撞地生存着...

akka小集群（小项目）同时接入的长连设备到了50万，应对的实时状态查询持续保持在1.5~2万/秒。规模相当于一个中型的实时在线游戏了。水平扩展虽然没有什么问题，但接下来重点要对程序做些针对性的优化，同时完善fail-over。
不如：长连接怎么做的
邓草原：回复@i不如:akka io

在QCon北京2014的演讲视频：http://www.infoq.com/cn/presentations/akka-cluster-realization

Actor最关键的：状态只由消息异步驱动（发送者发完不管），单个actor串行地接受和处理消息，所以里面的状态不会被并行修改，因此actor总是并行安全的。并行表现为很多actor同时活动。
@老师木
了解了一下scala， actor,思想应该说和go的coroutine是差不多的，都用轻量级进程，避免call back，chan和mailbox似，语言层面对并发提供支持，immutable,closure。感觉这应该是写分布式程序的大势所趋，所谓生产力高。但我猜测他们相对于c,c++缺乏对细节的操控。请教以上理解有没有问题。	

前段我们的akka集群在遇扰动时可能会陷入状态混乱。Akka使用gossip协议来协调状态（我知有不少人对此有疑问），我花了些时间来了解akka.remote和akka.cluster的实现细节，也查了一些akka设计的决策过程。这里是一份影响了akka设计的论文列表O网页链接。图则是我们akka集群当前的拓扑。

单独从每一部分看，akka的各项实现，包括failure-detector, cluster/member status, remote actor等等都非常出色，但组合到一起后仍有一些细节需要检验和调整。我们恰好用到了akka cluster方方面面几乎所有的功能，成为了先行者也自会成为领先者。BTW, Akka几乎满足了我对并行、分布式系统所有的想像。

以remoteActor的association为例，它的失联与节点unreachable是两个问题，但又相关。Akka team对是否允许unreachable的节点重回recheable就review过几轮，并最终有个可操作的方案。而对remoteActor的watch又不同。最终要把如麻的分布式系统理清在实践中还是有陷井。Akka在努力为大家趟这些陷井。

确实很少见粒度如此细的集群。比如你可以remote watch另个节点上的十万个actor，而且想快速响应，这时可能额外处理的心跳就达十万每秒…… Akka有这个能力，但实践中关键看你怎么用。//@glorysdj:akka且处理逻辑粒度太细…//@天下无霜_BBX:mark

果然是个stupid的错误。现在挂掉一个节点，actor顺利地在另一个节点上重生；再把节点起起来，actor又正确地迁回到这个节点。Akka集群几乎所有的功能点都调通了。
@邓草原
感觉程序又被我改傻了。傻了傻了。
shell0dh：为什么还需要迁移回来？如果重生节点资源充足。是不是不需要迁移回了？
邓草原：回复@shell0dh:当然要迁回来，这是水平扩展的online rebalance
shell0dh：回复@邓草原:迁移的话不会影响，前端请求中断或延迟么？
邓草原：回复@shell0dh:除了突然shutdown时正在传递的消息可能丢失，正常情况下，包括graceful的down，都不会有消息丢失（actor有暂存机制）。延迟则是难免的。
shell0dh：回复@邓草原:突然shutdown意思是说。机器断电之类的吧。这种正常调度迁移，是不会有消息丢失对吧？
邓草原：回复@shell0dh:是的。正常调度不会丢。当然，akka也提供持久化机制在异常挂掉时也可保证消息不丢。
小稻640：Akka 下 actor 可以进行迁移了么？
邓草原：回复@小稻640:我写的就是。

Akka到目前用了5年时间。当然他们的员工一辆校巴就坐下了。//@老师木: 请问如果重造轮子，谁能做到这个程度。

Scala: Next Steps: http://scala-lang.org/news/roadmap-next/

也可看看@简悦云风 在做的，总体上跟我们要实现的需求是相似的 //@邓草原: Akka到目前用了5年时间。当然他们的员工一辆校巴就坐下了。//@老师木: 请问如果重造轮子，谁能做到这个程度。//@邓草原:fix. 现在挂掉一节点，actor顺利地在另一个节点上重生；再把节点起来，actor又正确地迁回到这个节点。

Netflix 的性能架构师的 Linux Performance Tools slides: http://www.slideshare.net/brendangregg/linux-performance-tools

Miles Sabin forked Scala 这证明了 Scala 目前已取得的成就，也即，它实在是可以作为很多研究的出发点。同时也证明，越去到具象的层面，越难有共识。Sabin 比较轴，以前也跟我争论过。对于他的兴趣和方向来说（typeful functional programming styles ），这是不错的选项，尽管或者应该换个名字。

My Q&A with Typesafe: Akka at Wandoujia. https://www.typesafe.com/blog/qa-with-caoyuan-deng-akka-at-wandoujia

我现在通常把 Event 和状态放在一起想，或者，讲到 Event 时，倾向于说的是可能对状态产生影响的那些 Message。
@蔡学镛
过去在计算机系统内，往往 Message 和 Event 混用，但我发现现在似乎渐渐形成这样的习惯：Message 专指两个封装之间传递用的信息，用来解耦，而 Event 专指内部流通的信息、
张家浜河道玩航母：对，message是“中性”的，强调了传输数据本身，event则是对客体有“影响性”的message。

对于 Actor Model，非阻塞事件驱动只是它实现方式中比较重要的一块。我觉得最重要的是 Actor 因其理念而成为与位置无关、可以很自然地分布部署的、并行和增量计算的最小颗粒。 //@文艺复兴记:我最近也看了些Akka和Actor模型的资料，没感觉到什么新东西，不管是C++还是Java中，早就在大量使用类似的非阻
@并发编程网站
【AKKA文档——角色系统】角色是封装了状态与行为的对象，它们通过交换放入接收者信箱的消息实现两两之间的通讯。从某种意义上说，角色是最严格的面向对象编程，不过最好还是把它们当作人来看待。译者：@runningW http://ifeve.com/akka-doc-java-actor-systems/

如果你想看看 Akka Stream 中的 flow graph 现在实现成什么样了，可以看看这里：https://github.com/akka/akka/blob/akka-stream-and-http-experimental-0.7/akka-stream/src/test/scala/akka/stream/scaladsl2/FlowGraphCompileSpec.scala

Piper 将在 ReactConf 讲 How do we query fast moving data?：Data is moving. Data has always been on the move, the fact that when using computers we often need data to stand still in order to do something with it is usually a reflection of our lack of skill. http://lanyrd.com/2014/reactsf/sddwwg/

Reactive Manifesto 2.0 O https://www.typesafe.com/blog/reactive-manifesto-20 #论语汇的重要性# 里面对 Message 和 Event 也有一种有意思的区分: The difference being that messages are directed, events are not—a message has a clear addressable recipient while an event just happen for others (0-N) to observe it.

Domain-Driven Design（DDD）提出来有十年了吧，一直冷。但最近 Akka 圈子里却时常提及。DDD 希望能从业务域就把模型和逻辑设计清楚（业务模型和逻辑是最稳定的），但在实现中却一直找不到好的对应。而 Actor Model 似乎提供了一个不错的对应。（Domain 里有什么，实现中才应该有，也应该有）

Jonas Bonér 最新版本的 Road to Akka Cluster，非常值得思考分布式计算的同学一读：http://www.slideshare.net/jboner/the-road-to-akka-cluster-and-beyond

回复@电传幽灵:从以前的所谓的具体设计方法论来说，是。但从理念上来说，是正确的，实际上这十来年我自己一直是这样去做设计和实现的，即：Domain 里有什么，实现中才应该有，也应该有。能做到这种对应的设计和实现是最稳定的。 //@电传幽灵:鸡肋
@邓草原
Domain-Driven Design（DDD）提出来有十年了吧，一直冷。但最近 Akka 圈子里却时常提及。DDD 希望能从业务域就把模型和逻辑设计清楚（业务模型和逻辑是最稳定的），但在实现中却一直找不到好的对应。而 Actor Model 似乎提供了一个不错的对应。（Domain 里有什么，实现中才应该有，也应该有）

遇阻塞就交给外部，然后等外部消息通知（这也是 coroutine 的常态）//@老师木:我在想，一个更合理的设计是：coroutine所做的是一个独立的生态系统，里面完全没有阻塞操作，只有对数据的加工。而IO等阻塞操作外这个coroutine系统外部，负责给那个系统灌数据和接受结果。
@左耳朵耗子
好多人认为Go的goroutine就是coroutine，其实并不是。它们最大的差别是，coroutine最致命的是OS系统调用，因为大多数的系统调用都是阻塞的，所以一旦一个协程被系统调用阻塞住了，CPU无法被yield出来，而go程不会，在系统调用被阻塞时会马上切换另一个go程调度。

JVM 下是调度线程来执行 actor，所以线程会有上下文切换，但 JVM 的这个切换已经在微秒级。//@老师木: 现在常见的实现应该在coroutine内部完全没有context switch吧？//@邓草原:遇阻塞就交给外部，然后等外部消息通知（这也是 coroutine 的常态）
@左耳朵耗子
好多人认为Go的goroutine就是coroutine，其实并不是。它们最大的差别是，coroutine最致命的是OS系统调用，因为大多数的系统调用都是阻塞的，所以一旦一个协程被系统调用阻塞住了，CPU无法被yield出来，而go程不会，在系统调用被阻塞时会马上切换另一个go程调度。

不同 OS 的实现不尽相同，不过我真方面我不是专家 //@老赵: JVM的线程不是OS线程吗？为什么会由JVM来切换？//@邓草原: JVM 下是调度线程来执行 actor，所以线程会有上下文切换，但 JVM 的这个切换已经在微秒级。//@老师木: 现在常见的实现应该在coroutine内部完全没有context switch吧？

Actor 接收到消息，然后做相应操作，这段过程会调度/绑定到一个线程执行，处理完毕，让出线程，转入等待下一个消息的常态。如该相应操作本身是 CPU heavy 的，过程中占用线程是免不掉的。如果是 IO，可使用 nio，向 nio 接口注册或发送数据/引用，然后让出线程进入常态，等待 nio 操作完毕的回送消息。
IO 操作放在 Future 里就好了，Future 默认会在 actor 线程池之外的线程池中执行的印象。IO 线程池和 CPU 线程池分开会更好。
Erlang 中跟 IO 相关的库都专门写过了。Akka 中主要的跟网络 IO 相关的也有了 akka-io，文件 IO 我自己写过。当然大部分真正要处理的 IO 还是通过网络在别处的资源。

一个scala变量和invokevirtual指令问题，问题描述在此：https://gist.github.com/shijinkui/fdf1c48669dd30626195
Named parameters 是由编译器在生成字节码前的某个 phase 就处理好的，简单点说就是按方法签名并根据参数名字重新排好就行了，等到了最后生成字节码的阶段就当然一致了。第 2 个问题有什么疑问吗？对 Java 和 Scala 都会是一样的。//@hongjiang_wang: google named parameters

在具体应用中 IO 操作通常会包装在 Future 中，Akka 里的 Future 是用 Actor 操作的，而 Future 提供了将相应的回调业务写在一起的接口。akka-io 包则提供了包装好的 nio。
@邓草原
Actor 接收到消息，然后做相应操作，这段过程会调度/绑定到一个线程执行，处理完毕，让出线程，转入等待下一个消息的常态。如该相应操作本身是 CPU heavy 的，过程中占用线程是免不掉的。如果是 IO，可使用 nio，向 nio 接口注册或发送数据/引用，然后让出线程进入常态，等待 nio 操作完毕的回送消息。

201410

spray-scoketio 开始用 akka-stream 替掉 rxscala。https://github.com/wandoulabs/spray-socketio/commit/29a75c13601e46c2a033e075ddf49b57af65b19f

关于 #monad#，有许多种描述，以前在 http://weibo.com/1875401263/Aqeofzg0A?mid=3768250619720289&ouid=1875401263&type=comment 中我说过一种角度，而 eed3si9n 在最近的博客中则从分形的角度做了一种描述，要点是：“Monads are self-repeating structure like fractals”。http://eed3si9n.com/monads-are-fractals

从坑里出来了。整个 spray-socketio 现在解耦成清晰的三个部分，Transport / Session / Namespace，可以在一个集群内，也可各成集群。其中 Namespace 就是一个可以 scale-out 的 MQ。而业务逻揖仍在外面，从集群收发消息流，并围绕消息实时处理业务。

扫了一眼里面的评论，关于里面同学对大量 actors 实例下 map 大小的担忧回答一下：sharding actor 依靠 shardResolver 将 actors 分布到 n 个 region，这个分配靠一个简单的（通常是哈希 + 模）的算法就行，而 n 的数量可以自己定，每个 region 有自己的 map，大小可以通过 n 来控制。
@InfoQ技术 以Akka为示例，介绍Actor模型】许多开发者在创建和维护多线程应用程序时经历过各种各样的问题，他们希望能在一个更高层次的抽象上进行工作，以避免直接和线程与锁打交道。这篇文章里，我们来了解一下Actor模型的原理，并进一步探索了Akka工具所提供的各种特性。Ohttp://www.infoq.com/cn/news/2014/11/intro-actor-model
(续）简言之，actors 至少按两级做分配，第一级不靠 map 而是靠计算，第二级才是 map 。这个分配机制简单有效，足够处理上亿个 actors 了。
更正一下。第一级也有 map，key 是 region id。一个大数尽量均匀地拆成 n x m， n 和 m 都大大减小了。

仔细想过后，Akka 中还是存在 ”有一个 Actor“ 的 pattern，我把它暂时命名为 Reactor。与 “是一个 Actor” 的 actor 相比，reactor 也由消息异步驱动，但在一束相互关联的 reactors 之间，一个消息处理周期可以驱动这些 reactors 完成一系列关联的动作，这些动作可由相互间的_直接调用_完成。

花了几个小时修改跟 Typesafe 的那篇英文 Q&A （https://www.typesafe.com/blog/qa-with-caoyuan-deng-akka-at-wandoujia）的中文译稿，这样一来，恐怕表达得不如英文了。

事件流 → 状态快照 → 时间序列。到昨天走通了所有环节。

昨天跟 @连城404 谈到 JVM 下的 GC。Actor 模式下我们倾向于：绳命常驻的 actors + 转瞬即逝的 messages，这两种都是利于 GC 操作的实例。
但是对于用于计算的child actor如何对待，开着，放那儿，有消息时干活儿，还是应该有需要的时候起起来，没用的时候通过passivate 关掉？
:好问题。计算用的 actor 假如是 stateless 的，且假如根据压力增加或者减少，那当然就有 GC 问题。不过，这种 actor 既然无状态，就不会占多少内存，一直放在内存里也无所谓。其实，这些 stateless actor的数量通常都会在tuning 时与stateful actor的数量做好匹配。然后scaleout就是。

若FP能大量缓存已执行过的params + result //@连城404:函数式语言：0. 单次赋值（有利单线程内高效GC） 1. actor间严格隔离，仅靠消息传递通讯（GC不用stop the world）2. 语言级高度集成的高并发支持（将GC间隔充分打散）3. 静态强类型 4. Java、OCaml，乃至C/C++级别的计算效率 4. 彻底干掉OOP遗毒
@邓草原
昨天跟 @连城404 谈到 JVM 下的 GC。Actor 模式下我们倾向于：绳命常驻的 actors + 转瞬即逝的 messages，这两种都是利于 GC 操作的实例。

Mark 下底下的讨论：http://weibo.com/1560442584/BxL05ECWu?mid=3780496024430503&omid=3780444287819736&ouid=1875401263&rouid=1875401263&type=comment //@老赵: 话说把消息从这个线程发送到另一个线程，会不会影响GC啊？ //@邓草原:若FP能大量缓存已执行过的params + result //@连城404
@邓草原
昨天跟 @连城404 谈到 JVM 下的 GC。Actor 模式下我们倾向于：绳命常驻的 actors + 转瞬即逝的 messages，这两种都是利于 GC 操作的实例。

豌豆荚邓草原：如何实现实时响应式平台】本文为Typesafe采访豌豆荚平台架构师邓草原关于如何使用Akka来实现实时响应式平台的经验文章。分享供开发者思考
http://www.csdn.net/article/2014-11-21/2822770-wandoujia-Typesafe-Akka

事件流 → 状态快照 → 时间序列。这是第一乐章的三部曲，在预期时间内完成了。这一年来时间主要用在厘清和实现这个架构，没有太多时间看书。今天订了几本，其中有《计算机网络：一种开源的设计实现方法》，回到最原始朴素之处去看消息流传中可能遇到的问题。还有就是 DDD 相关的，也是一种回溯。

规律隐藏在时间或者说不同尺度的周期里。周期对孤体而言也许意义不够深刻，但对集体行为则是关键。关乎交互、关乎协同，所以关乎规律。

回复@fleuria:“逻辑就凝固在事件里了” -- 这是为什么我要区分出“事件 - 状态 - 时间序列”几个阶段。在不同阶段，逻辑都不同，而业务需求围绕这几个阶段分别在外部实现。
@邓草原
事件流 → 状态快照 → 时间序列。这是第一乐章的三部曲，在预期时间内完成了。这一年来时间主要用在厘清和实现这个架构，没有太多时间看书。今天订了几本，其中有《计算机网络：一种开源的设计实现方法》，回到最原始朴素之处去看消息流传中可能遇到的问题。还有就是 DDD 相关的，也是一种回溯。

事件驱动实体状态变化，对实体状态快照的采样形成时间序列。所有业务逻辑围绕这条主线来展开。
@邓草原
事件流 → 状态快照 → 时间序列。这是第一乐章的三部曲，在预期时间内完成了。这一年来时间主要用在厘清和实现这个架构，没有太多时间看书。今天订了几本，其中有《计算机网络：一种开源的设计实现方法》，回到最原始朴素之处去看消息流传中可能遇到的问题。还有就是 DDD 相关的，也是一种回溯。

如何使用Scala的Singleton机制来表达Class-level的数据。http://8204129.blog.51cto.com/8194129/1588820
在这里 singleton object 的用法是实现某类 class 的实例的聚合数据。而在集群 level， Akka 也有对应的 pattern，叫 cluster singleton，可以用来实现跨节点的分片 actors 的数据聚合。

VM 生态下的好处：给 Akka 集群的 actors 加了用 JavaScript 写点脚本做点什么事的支持。Sharding actors + avro record + avpath + nashorn，这个跟 Redis 比，比之如何？
@邓草原
JDK8 #Nashorn# 若 ENGINE_SCOPE/GLOBAL_SCOPE 的 context 不含可变状态，且 script 中也不定义跨 functions 的共享状态，则 compiledScript 是线程安全的。这时可把 compiledScript 想像成一个接口是 evel(bindings) 的 pure function，而每次 eval 则是用 bindings 传给这个 function 一个参数集。

分布式动态内存数据查询引擎。

试下这个在 Google Doc 上的：https://docs.google.com/document/d/1nPMMIcUd7yXxXikdyc9cKRo1GkTQ5c8K9_8hj-464YE/pub //@bxeldor: @邓草原 论文列表链接失效
@邓草原
前段我们的akka集群在遇扰动时可能会陷入状态混乱。Akka使用gossip协议来协调状态（我知有不少人对此有疑问），我花了些时间来了解akka.remote和akka.cluster的实现细节，也查了一些akka设计的决策过程。这里是一份影响了akka设计的论文列表O网页链接。图则是我们akka集群当前的拓扑。

直接_基于 Akka 构筑的实时流处理引擎，数据按 DAG 流过即处理完毕。我们在构建的架构有个关键点与此不同，就是数据流过时中间状态及历史一直要求留驻在节点中，更像是一个实时数据流驱动的状态机。
@钟翔clockfly
技术白皮书：基于akka的实时流处理引擎设计："GearPump_Final_intel.pdf"，快来看看吧 http://vdisk.weibo.com/s/CfjtiUEtNG_En/1418693324
:目前只有 Typesafe 同我的访谈中谈及了部分。在微博上也有些只言片语。较完整的内容在公司内部不断更新的设计文档中。目前没有完全按照一个通用框架来设计，也许本来就不需要是完整的通用框架，只需要泛化的思路和库。

Asynchronous and non-blocking Scala native driver for Apache Cassandra: https://github.com/ekalyoncu/vangas-cassandra

翻译了一篇Akka的简明教程，欢迎阅读扩散。@ImportNew @InfoQ @developerWorks @fei0_0fei 并cc @邓草原 老师。http://hongbinzuo.github.io/2014/12/16/Akka-Tutorial-with-Code-Conncurrency-and-Fault-Tolerance/

AvPath 在这里了：https://github.com/wandoulabs/avpath。一个类 XPath / JSPath，针对 Avro record 的库。这也是个小型解释型语言的例子，见 Parser.scala 和 Evaluator.scala。

最近对Akka比较感兴趣，于是乎小研究了一下它的源码，写了一篇博客从源码级别介绍了一下Akka中创建Actor以及处理Actor邮箱消息的基本过程，求轻拍~~http://www.nyankosama.com/2014/12/15/akka-source/

这是 Scala中类似： { x => x match { case xxxxxx => ...} } 的句式总是可以缩写为：{ case xxxxxx => ...} 的自然结果，请看我在博文后的评论或 https://gist.github.com/dcaoyuan/f3aed1311a86f6739b14 //@连城404: 赞，文中第一个例子是我一直困惑但没有细究的问题//@FuqiangWang: 转发微博
@hongjiang_wang
scala scala雾中风景(21): auto-tupling与auto-detupling http://hongjiang.info/scala-pitfalls-21-auto-tupling-and-auto-detupling/
不过博主谈的其实应该是调用时为何 p(1,2) 和 p((1,2)) 都行，也即若 -Yno-adapted-args，则 p(1,2) 编译不过

akka-stream 和 akka-http 的文档终于出来了：http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala.html

akka 的 timer (scheduler) 是基于类似 Hashed Timer Wheel 的实现，或者说用一个线程（也可多个）来执行一个在相应间隔处装填了 tasks 的转轮，并在 tasks 转到激发处时触发任务。好处是一个 scheduler 就可以满足很多定时任务，缺点是如果在一次转动中不能完成所有任务就可能会有任务 slip。
@淘宝褚霸
erlang VM的timer是个核心软性资源，定时器存在几个问题 1. 数目过多对系统性能的冲击。 2. 程序bug导致timer数目不可控。 3. 程序bug导致timer时间过小。这些问题需要监控起来, 预防起来。
（续）akka scheduler 的时钟轮虽然在一次转动中若不能完成所有任务就可能会有任务 slip，但 akka 鼓励这些任务只做一件事：发一个异步消息，具体的任务则由 actor 在收到这个消息时再处理（会有另批线程来调度这些任务），而发一个异步消息是很便宜的，这样就可以避免前面谈到的缺点。（完）

Variable 通常译为“变量”，对计算机领域的人而言，在接触到 mutable variable 和 immutable variable 后难免感到困惑。其实，在数学上，尤其是代数，variable 可指用来代（替）数的符号，或者说它可被绑定到某数值。在计算机领域，则可看作引用（指代）某值存储地址的符号。因此"变"实为“可代”。

Adventure 2014: 1. Spray-WebSocket; 2. Spray-SocketIO; 3. AvPath; 4. Akka based distributed status service; 5. Refined time series reactor; 6. Supported SBT project on NetBeans; 7. Grasped stream.

想整个 avds (Avro data server based on Akka)，有 spray-can 上实现的 HTTP REST API，初测一下，这个 API 的 select 性能在本笔记本上是单机每秒 1 万左右。本想找个 redis 的 HTTP 接口比较一下，结果找到的 webdis 似乎不行，不知现在哪个是最好的。
性能其实够用了，重点解决的是 HA 和 scale-out，从这个角度说，有 avpath 能力的 avds 是有价值的。
再看了一下，瓶颈其实是在把结果转换为 JSON 处，JSON 库是老的 Parboiled 的，去掉这块可到每秒 4.6 万，换 JSON 库就是了。足够了。另，一个 redis 实例在本机上是 9.3 万。

Java 程序员入门Scala 不难，很快可写出跟写 Java 时差不多的代码。可你很快就要读到别人写的 Scala，这时最困难也还不是函数式编程部分（这块适应一下就会有感觉），而是那些看起来有些困惑的技巧的运用（这也是 Scala 编程最有趣的部分）。这时《深入理解 Scala》是一本非常合适的指导。（我刚买到） scala in depth

Martin 等人的这个系列讲述的是设计 Scala 的理念，对于理解 Scala 很有帮助。
@动物庄园上校
Scala 概述 （四） 操作也是对象 OScala 概述 （四） 操作也是对象  http://weibo.com/p/1001603799614535897626

每次 map 更新后就不再是原来的那个 map，这是 immutable 本来的要求，也即，至少，原来你引用的那个“旧的” map 还是没有变。至于取值的线程拿到的是否最新的数据，这不是 immutable 的任务，或者说，那要通过加锁或者象 actor 模式等策略来保证。
@ice默一生
深入理解scala勘误 第二章2.3选择不变性中的例子应该是错的，为了说明不变性的优点将HashMap替换成ImmutableHashMap，但是变量本身还是可变的，在多线程环境下可能导致变量读取到的是旧值，例子见图 @诺铁_大魔头 @邓草原 这样理解应该没有问题吧？

对 #astore# 做了点性能调整，在一台双 CPU (Intel Xeon E5-2420) 共 “24” 核的服务器上，REST-JSON 接口现在可以到 GET 7.8 万 [#/sec]，PUT 6.5 万 [#/sec]。这台机器上简单的 ping/pong HTTP GET 可到 13 万 [#/sec]。不过现在 CPU usage 似乎不到 50%，原因待查。https://github.com/wandoulabs/chana/wiki

Jonas: Call it Fast Data. Speed is the hardest problem to solve—getting in-memory cached, real-time processing of data. When analysis needs to be done on the fly, on live data streams, with real-time feedback to systems, there are a host of major challenges. https://adtmag.com/blogs/watersworks/2015/01/2015-dev-predictions-part-1.aspx

仔细观察 top -H， 在 dispatcher 数为 6 时，这 6 个线程各自能接近 100%，还有一个 io 的 selector 线程则一直不甚饱和。其余用到的线程都不到 10。但增加 dispatcher 数则发现这类线程的 CPU usage 反倒开始相应下降，总的 throughput 也开始变差。就是说 6 个正合适，多了也没用，瓶颈似在他处。
@邓草原
对 #astore# 做了点性能调整，在一台双 CPU (Intel Xeon E5-2420) 共 “24” 核的服务器上，REST-JSON 接口现在可以到 GET 7.8 万 [#/sec]，PUT 6.5 万 [#/sec]。这台机器上简单的 ping/pong HTTP GET 可到 13 万 [#/sec]。不过现在 CPU usage 似乎不到 50%，原因待查。

找个时间看看 #astore# 里的 DistributedStatusBoard 要不要/能不能用 akka-data-replication 来实现。https://github.com/patriknw/akka-data-replication

上篇说到，在一台 24 核的机器上 #asore# 只能压满 6 个线程，即猜某处可能存在一个 X 对 6 的瓶颈。这几天时不时想起这事，也试过几个方案但都未找到这个瓶颈。今天喝完羊肉汤，再扫了一眼代码，就找到了。这是修改完毕的结果：GET 17 万每秒，PUT 10 万每秒。https://github.com/wandoulabs/chana/wiki

一个月，#astore# 初成。除持久化，已是一个分布式的结构化数据内存存储。设计要点：1. 每条记录是一个 actor；2. akka 的分片集群扩展；3. avpath 深度定位数据；4. 字段更新时调用 js 脚本。因为是 REST-JSON 接口，@aimingoo 用 node.js 演示过有趣的状态转换用法，也 push 了项目的需求和设计。

回复@连城404:除了可以在某些场景象使用 redis 一样使用，更重要的是用来做实时状态计算和存储。另外，这个框架除了可以当作服务直接运行，也可以当作是 lib 用来扩展。 //@连城404:呵呵，果然如那天在ThoughtWorks所说，有用作OLTP的潜质 :-) //@邓草原:完了，一大波需求又要接踵而至。

HT线程，这节微博 http://weibo.com/1875401263/C0wXu12Ej?mid=3803432270417442&ouid=1875401263&type=comment 中，我其实还想搞清 12 个物理核在 HT 成 24 “核” 后，CPU usage 在高并行的程序下究竟会是什么表现。这篇是我找到的较有参考价值的（包括其后的评论）：「HT - how does it double CPU throughput 」https://www.percona.com/blog/2015/01/15/hyper-threading-double-cpu-throughput/
在解决瓶颈后，核的利用率从 6 到 了 20 （80% CPU usage on 24 核），而 每秒 GET 数从 7.8 万到了 16.9 万，简单的估算：16.9 / 7.8 (=2.17) < 20 / 6 (= 3.33) ，不（会）是线性的。以后有时间也可以从 1 到 22 个线程（留 2 个给 nio 的 selector）做一次完整的测试。

akka-persistence 提供 journal 和 snapshot 两种机制，跟 redis 的 AOF 和 RDB 类似。不过 akka 的持久化也跟它的其它操作一样，粒度可以控制到每个 actor。究竟这样的粒度实现起来会是什么样的表现呢？我打算在 astore 上尝试一下。

校好了。
@动物庄园上校
Scala概述 （六） https://github.com/wecite/papers/blob/master/An-Overview-of-the-Scala-Programming-Language/6.Composition.md 还是整理好了基本格式，等待进一步美化

HT线程 对 astore（akka） 在 HT 下的并发特性做了个更全面的测试。客户机上同时开 4 个 ab 进程。设置 akka 中 2 个固定用于 nio selector 的线程，然后从 1 开始逐渐增加调度 actors 的主线程数（parallelism），出来下图曲线。可见，在 13 个主线程前，基本为线性扩展。从 18 个开始则 CPU 已满。
2 个用于 IO 的线程最大在 60% 左右，并不饱和，数据传输量最后在 40MB / s 。测试中每个参数连续跑 10 次，去掉开始和结尾各 2 次，取中间的 6 次做平均。

@简悦云风 这是做的比较全面的一次测试，IO 似乎并不是瓶颈。可能跟你的场景相比，你可以绝对控制进（线）程数，而我这里线程数除了固定的主调度线程（大约跑到 90%）和 io 线程（大约跑到 60%），还有一些其它的线程（大约跑到 10%），线程切换有额外的消耗。

从测试情况看，至少对于使用 fork-join 调度的 akka 服务，在开了 HT 的 linux 环境下，CPU 是可以压到 100% 的，只是在超过 50% 后，不再是线性增加，而这个空间大约还有 25%：http://weibo.com/1875401263/C1AdF48Jh?mid=3803789717367567&ouid=1875401263&type=comment#_rnd1450859967883

astore 测了一个跟 redis 的 memtier_benchmark 数据大小相近的指标（不过是用 REST-JSON 接口）。四个 ab 共 100 个连接、2000 万次请求。随机 GET 300 万条 50 Bytes 大小的数据。结果：12.5 万 / s；平均响应时间 0.813 ms， 98% 在 1 ms 内，99% 在 2 ms 内；CPU 100%；数据传输量 28MB / s。

翻译Scala，喜迎新年，Scala概述全部翻译完毕：https://github.com/wecite/papers/tree/master/An-Overview-of-the-Scala-Programming-Language

测了 akka 分片集群（用 astore）在 10 个节点的树莓派 2 集群下的性能，几乎是线性 scale-out。想了一下要点：#akka分片集群可以从任一节点访问整个集群所有节点的数据#，或者说每个节点本身也同时是 proxy，近乎线性的 scale-out 能力是合理的。

Akka 分片集群水平扩展能力分析」：跟很多分片集群解决方案不同，akka 分片集群中每一个节点都在直接访问本地数据的同时，也都可以作为 proxy 访问集群中其它节点的数据。在我看来，这是 akka 分片集群水平扩展能力可能接近线性的关键。 PDF 在这：O网页链接

继续ngx_cc，这次发的是ngx_cc的架构详解。有兴趣的请前往：https://github.com/aimingoo/ngx_cc/wiki/ngx_cc%E7%9A%84%E6%9E%B6%E6%9E%84

Akka actor 的消息一直是 un-typesafe 的，对于 Typesafe 来说这始终是个情结。在经过多年的尝试，包括后来放弃的 2.2.x 中的 Typed Channel 后，Akka Typed 项目终于逐渐成形。Akka Typed 带来了重大变化，因此在出现于 2.4-snapshot 后仍将在一段较长时间里标为 experimental：http://doc.akka.io/docs/akka/snapshot/scala/typed.html
往好处想想，消息类型是 Any 时编译速度非常快。。。//@连城404: 这个不是处女座情节，原本大型 Akka 项目重构的时候会很痛苦。因为消息都是 Any，等于退化到 Python、Ruby 等动态类型语言了。重构的时候无法借助编译器检查。//@黄涧石: 这是何等处女座情节啊！

Akka Typed 新的 actor 实现，从以 actor 为轴心转为以表达 protocol 的 message type 为轴心，在我看来，这更加接近了 Type 的本质定义：_Type = A Set of Interfaces_。Akka Typed 不但可以表述 Java Object 风格的 methods，而且，其行为 Behavior 还可以“动态”地 narrow 或者转换。Well done.

注：整理此文并不意味着本人同意文中所有观点。比如，我一直没太把 Storm, Samza 和 Spark 放在心上，对 Kafka 也不甚满意。当然，我对 HBase 也不满意，对 GlusterFS 也不太满意。但对 Scala，Akka 很满意，对 Riak 和 RabbitMQ 也很满意。而且，不满意并不意味着我不用，满意也不代表就一定用。
@邓草原
偶然在网上看到一位台湾网友 ccshih 的文字，短短的篇幅介绍了分布式系统的若干要点。觉得还不错，就整理了一下（附图是部分内容）。完整 PDF 地址：http://dcaoyuan.github.io/papers/pdfs/Scalability.pdf

要实现这个 Typed 的语义和上下文（编译时），不是那么容易的。所以说：“万能”的 Scala 。
@邓草原
Akka Typed 新的 actor 实现，从以 actor 为轴心转为以表达 protocol 的 message type 为轴心，在我看来，这更加接近了 Type 的本质定义：_Type = A Set of Interfaces_。Akka Typed 不但可以表述 Java Object 风格的 methods，而且，其行为 Behavior 还可以“动态”地 narrow 或者转换。Well done.

这是初看 Akka Typed 文档和示例代码的第一感觉，就是，似乎看不到显式定义 Actor 的代码了，而是，你在某个 context 中定义接收/返回的消息类型（协议）。这个 context 也很有意思，不像静态决定的方法，它还带来某种动态的行为转换能力。刚看到 Jonas 在 Twitter 中转了我的看法，看来我理解得没错。
@邓草原
Akka Typed 新的 actor 实现，从以 actor 为轴心转为以表达 protocol 的 message type 为轴心，在我看来，这更加接近了 Type 的本质定义：_Type = A Set of Interfaces_。Akka Typed 不但可以表述 Java Object 风格的 methods，而且，其行为 Behavior 还可以“动态”地 narrow 或者转换。Well done.

里面的「Scala 初学指南」翻译得不错。https://windor.gitbooks.io/beginners-guide-to-scala/content/index.html
@Hawstein
[20150315 - 20150321] Scala 周报 - ScalaChina ScalaChina:Scala中文社区 http://scalachina.org/topic/550ab36b84ddfe6644e8c92e

有关 partition 数和 comsumer 数，较好的解释可以看： https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-HowdoIchoosethenumberofpartitionsforatopic? //@wptree: kafka(3) “Consumer Group里的consumer数量不能小於partition 数量...”容易造成误解：一个group里面consumer数量是可以比partition的少的，只会造成消费不均匀，而不会造成某个partition的数据无法消费的问题

Kafka 本身是一个涉及分布式数据的持久化、分布式数据的生产、分布式数据的消费，以及这些环节的协调、匹配的复杂的分布式系统，所以对它的理解也好、使用也好，还是有些绕的。我会找时间专门写点东西来解读，也会顺便加一些注解到这份 PDF 中。
Update 1 增加了注解：准确地说，是一个 partition 只能同时被同一 consumer group 中的一个 consumer 消费，这样可以保证这个 partition 对于同一个 consumer group 来说不会被并发取。
Update 2：虽然一个 partation 应该只绑定到同一 consumer group 中的一个 consumer,但一个 consumer 是可以同时绑定到一个以上的 partition 的,只是,是否这么处理,取决于你是否认为消费端的并 行能力能够适配多个 partitions。那么,partition 和 consumer 的数量究竟应该是怎么样一个关系呢? -待续
续1) 假设, partition 数量为 n, consumer group 中的 consumers 数量为 m,结合以上两点,我们可以得出,合理的配置是:m <= n,因为,每个 partition 只能绑定到 1 个 consumer,也即,最多只会有 n x 1 个 consumer 可以绑定到 partition,如果 m > n， -待续
续完) 就会有 m - n 个 consumer 是不会绑定到 partition 的,也即,不会接受到数据。注：这些 Updates 已经注解到 PDF 中（重新下载即可看到），也欢迎指出文中其它的错误，我会在核实后继续注解到 PDF 中。http://dcaoyuan.github.io/papers/pdfs/Scalability.pdf

这可能是典型的 consumer 能力不匹配所致，可以参考：https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Whymessagesaredelayedinmyconsumer? //@louzhu楼主: 如果m<n 且 producer 的并发较多，可能会出现部分 parition 的 msg 无法得到实时的消费（kafka 的 consumer 貌似需要等到当前消费的 partition 在一个时间段内没有新的消息，才会去消费其它 partition 的消息)

推荐，Scala 是怎样帮助思考架构的设计的。内容比较多，是高老师一贯的风格，给你细细道来。http://www.cnblogs.com/SmartADT/articles/4365720.html

"Fearless Concurrency with Rust"：http://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html 一篇讲述 Rust 怎样让 concurrency 编程安全的文章。基于 ownership 概念（编译器负责保证）引伸出很多有意思的场景，让我想起以前微博中所说过的“状态总是应该属于某个主体的”：http://weibo.com/1875401263/BEcVvjIJC?mid=3830623371789090&ouid=1875401263

avpath 增加了用正则表达式访问 map 的 key 的功能 https://github.com/wandoulabs/avpath#map-key-predicates。最近在思考，跟关系表相比，基于 Object Graph 的查询表达式及返回格式始终没有标准，一个原因是关系表可以在理论上研究到比较透，而 Object Graph 的似乎有难度。返回格式方面，跟 @aimingoo 讨论过一个叫 JSON 片段的东西。

要让线程等待（比如为了同步），可以用 wait；要让 actor 等待，可以用 stash 。后者不会 block 线程，所以最好想办法将前者转换为后者。

Nginx has big plans for JavaScript: http://www.infoworld.com/article/2838008/javascript/nginx-has-big-plans-for-javascript.html。这个不算新闻了，不过今天和 @aimingoo 讨论，随着 nginx 越来越像一个 application server，nginx + js 以及 akka + js (比如 astore) 等，似乎能促成 js 成为一种分布式计算下最好用的脚本语言，用来给分布式框架注入和改变行为。
这里，nginx 适合用于不带状态的服务，而 akka 则可以用来存贮状态并触发和执行业务行为（分布式的）。两者如果能在 js 上达成一致的支持，再加上 JSON 以及 RESTful 接口，看起来是一个不错的、将各种业务粘合到一起的分布式架构。而 Node.js 则可以在其中担当些起粘合作用的角色。
回复@我是来测试的:比如，让 nginx 也支持 Scala 脚本就麻烦些。另外，js 目前的实现基本上是单线程这点也让 actor 中调用（运行一段 js）变得简单。 //@我是来测试的:回复@邓草原:当然, 都只是用很基本的scala语法. 不过, 现在会写几行js的人, 更多. 可能你还考虑到一些scala编译速度的问题吧.

aphyr 的 blog 有一系列对各种数据库 consistence 的分析文章： https://aphyr.com/，最近的一篇：Mongo’s consistency model is broken by design: not only can “strictly consistent” reads see stale versions of documents, but they can also return garbage data from writes that never..

回复@Apache9:还跟设计有关。Akka 下通常主要有两种对象：一种是瞬灭的消息，一种是长生的实体 actor，这两种都是便于 GC 处理的。而像 session 这种，可以考虑复用。另外，Java 8 的 G1 GC 已经很好用了。//@Apache9:跑在JVM上的语言一个gc就哭了吧。。。

关于 ORM，最近想了很多。从 FP 的角度看，关系模型可以不动，需要的是一整套 lazy 的 mapping 函数，然后就可以映射到 object view。这有些难度，即使从理论上我至今也尚未找到这个问题已完全解决的证据。但是，工程上总是可以对目标做些限定，从而渐进地抵达。我会试试。

可以这么理解。不过，系统本身在不被观察时按理应当自洽地怠速运行。只是，即使在自然界，没有交互的系统也几乎没有吧。//@软件攻城狮:这算是个观察者效应吧？
@邓草原
当我们试图得到系统的状态而又不阻塞系统时，得不到完全准确的状态。

对于具体的业务，可以或者说始终需要自己定制一部分。这时通常让每个 actor 自己定时报告自己的状态，同时也顺便提供相应的 API 可以从外部主动 ask 。
@hongjiang_wang
Akka的监控有什么好的实践？@邓草原

初步写完了 JPQL 的 PEGs 语法定义：https://github.com/wandoulabs/chana/blob/master/src%2Fmain%2Fscala%2Fchana%2Fjpql%2Frats%2FJPQLGrammar.rats，在各种形式的语法定义中应该是跟 BNF 最接近的了：https://github.com/wandoulabs/chana/blob/master/src%2Fmain%2Fscala%2Fchana%2Fjpql%2Frats%2FJPQL-2_1.BNF。没想到的是 JPQL 的语法定义比 Scala 的还长 15%：https://github.com/dcaoyuan/nbscala/blob/master/scala.core/src/main/java/org/netbeans/modules/scala/core/rats/ParserScala.rats
完整的编译器，写语法定义并生成初步的 Parser 是第一步；第二步是 AST nodes 的定义（初步的），体力活，基本上是将语法定义中的子句一一对应到目的语言：https://github.com/wandoulabs/chana/blob/master/src%2Fmain%2Fscala%2Fchana%2Fjpql%2Fnodes%2FJPQLNodes.scala；下一步就是转换到这个定义。

这样可以监控业务 actor 的状况，但 Akka 中尤其是集群场景下还有很多不是显式可见的系统本身的 actor 。因此最终还是需要一套系统级别的监控系统 + 业务级别的监控。Typesafe 将这个事情留给了第三方去开发。
@hongjiang_wang
对于缺乏backpressure机制的actor系统，mailbox的监控还是很有必要的，我们目前只想到了一种简单扩展，对enqueue/dequeue做个hook，不知道有没有更好的方式 http://hongjiang.info/akka-mailbox-counter-extension/

Event Sourcing Pattern 常采用 snapshot + subsequent event sourcing 的方式来提高存取和重演效率，其本质是一种有效的信息压缩。因此，对于由事件驱动变化的状态，可以。不过，有很多数据本身就是一个不断追加的集合，这种方式起不到压缩信息的作用，这时应该选择纯粹的 sustained event sourcing。

先写了个简单的 JPQL evaluator，对_单个_的 avro record 可以做简单的 select 和 where：https://github.com/wandoulabs/chana/blob/master/src%2Fmain%2Fscala%2Fchana%2Fjpql%2FJPQLEvaluator.scala，https://github.com/wandoulabs/chana/blob/master/src%2Ftest%2Fscala%2Fchana%2Fjpql%2FJPQLEvaluatorSpec.scala。下一步是先解决从整个集群中去查，并一点一点完成 Evaluator。

给集群喂一条 SQL （哦，是 JPQL），然后查询结果就会实时随着集群里实体的当前状态一直变化。//@王雨舟大Boat: 实时变化的sql结果
@邓草原
忙了一个多月，终于在 Chana 集群上实时查询出了第一个全局结果（JPQL on Chana ）。虽然简单但初步验证了设计。其实是说，接下来还有好多难点呀。https://github.com/wandoulabs/chana/blob/aec45a9ae29dba02194515492873cdd1e613367d/src/multi-jvm/scala/chana/ChanaClusterSpec.scala#L385
回复@Dongxu_Huang:不太一样，我们这个现在兼备类似 JavaEE 里 entity bean 的功能，当然实现跟 JavaEE 是完全不同的方案。

其实是有些联系的。连续的东西被离散化处理时总是难免联想到量子，这也许不是偶然的。//@pi1ot: 需要参考哥本哈根流派解释吗 //@邓草原:我持续不断地把带时间戳的快照推给你，同时给一个这个快照的准确概率，你自己去构造和适用这个快照序列的可靠性。//@红烧Lo:[笑cry]//@王四哥达家码: [doge]
@邓草原
分布式数据服务的一致性问题有些内生的矛盾，我在想要不要引入概率算了。

每个 entity 在 “自身变化时 + 定时” 报告自己的快照，这样可以保证观察到的聚合数据_高概率_是完全正确和校正过的（每次报告要求 ACK 也不能保证，还不如放弃） 。但对被 “删除” 从此消失的 entity，再额外强制 ACK。不管怎么样，人所能观察到的结果总是、要是（带时间的）快照。

花两天扫一下《数据库查询优化器的艺术-原理解析与 SQL 性能优化》。虽然对 JPQL on Chana 来说，很多优化问题已经不再成立。
 
咱们的方案对状态处理就很自然，而且生成时间序列也很简单。 O七牛是如何搞定每天500亿条日志的 http://mp.weixin.qq.com/s?__biz=MjM5NzAwNDI4Mg==&mid=211136387&idx=1&sn=b861d00ae41f993ee15e3fe9f745053f&key=0acd51d81cb052bc95ecbcfa63187eef872303c726e5eca6f8a3cc578ad1709eb3a2c9790319c7e724c9810bf0fc74d2&ascene=0&uin=ODI4MjczOTAx&devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.2+build(14C109)&version=11020012&pass_ticket=WqZgPuSJFtstSTwv1DTtqOJsx7rRVj65YNUC7JgZoL5CrhjBIDaIc4qd3bDT%2FRc%2B

JPQL on Chana, refreshing JPQL result in realtime, supported basic WHERE and aggregate functions now. https://github.com/wandoulabs/chana/blob/d68c9512f718d580dd3130c732f3f8012e3a7c84/src/multi-jvm/scala/chana/ChanaClusterSpec.scala#L390

JPQL on Chana，思路厘清，架子搭好后，咔咔就写好了 orderby, groupby, having。对于全部在内存的热数据来说，已是基本可用。现在有些后续优化的思路，包括冷数据的处理思路，不过得安排到本荚的下一个 Q 了。

想到一个表达 avro 投影的方案。
@邓草原
chana 用 avro 来存贮实体状态，但是用 parquet 来传投影？
把指定的 field 取出来拼成一个精简后的 schema，就这么个简单的事，实现起来却那么别扭，怎么了 //@邓草原:想到一个表达 avro 投影的方案。
我应该把它设计成 tree #别扭的原因找到了？# //@邓草原:把指定的 field 取出来拼成一个精简后的 schema，就这么个简单的事，实现起来却那么别扭，怎么了 //@邓草原:想到一个表达 avro 投影的方案。
终于写对了：https://gist.github.com/dcaoyuan/21b8f0289d65b833831f
传递投影时比 Parquet 还小

这个例子中 accumulator 每次都是一个新的量。有很多场景中 accumulator 是追加性质的，比如 linkedlist， sum 值等，这种情况下效率问题不大。尾递归消除则是满足一定条件时可以转换成带内部可变量的循环。内部受控的可变量不可怕，实际上只要不被乱引用扩散出去的可变量都不可怕。
@老师木
函数式编程#不可变状态#这个例子把循环改成递归，怎么消除可变状态的呢？每层递归返回时，还是需要有个变量接受和保存返回值的吧。
递归简化问题//@_nearly转1:一直闹不明白递归有什么好，循环不更可控？//@邓草原: 递归围绕最终结果及其中间值，每次调用返回的中间状态作为下次函数调用的输入，实际效果就是中间状态不断演变从而看上去像可变量。由此其实也可知，可变量是可以用递归的函数来表达。在 Erlang 中这点扩展到整个框架

按 JOIN 处理集合字段，能简化 KEY、VALUE、INDEX 函数，但会带来巨大的数据冗余，如果我能设计一种虚拟的多行结构呢？//@邓草原: 再想了一下，这些关键字是作用在 Map、List 上的，如果把 Map、List 看成是 JOIN （JPQL 是这样看的），似乎就自然了。
@邓草原
JPQL 的 KEY、VALUE、INDEX 关键字怪怪的，要实现起来不太自然呐，我去望会星空...

每个账户是一个 actor //@ubernetes:What is a typical use case of Akka? I know a little bit about Actor model and Akka, but never see any use case that it can make a difference. Say a typical bank system, how do you model deposit and withdraw with Akka?
@邓草原
两个基于 Akka 的产品，上线后分别运行 1 年多和半年多了，没有挂过。暂时地，目前升级时会主动 down，这是为了谨慎起见，因为也可以逐节点升级的。主动 down 时如果要做到服务不停，只需要配一个能应对升级或者回滚时间（比如 10 分钟）的小集群即可。

首先要定位脑裂是否是因为业务逻辑的设计和实现上的问题，比如每秒太密集的系统级消息、系统本身已经过载等等。在排除这些因素后，对由于网络、机器等导致的脑裂可以采取这些措施。
@netcomm2012
http://doc.akka.io/docs/akka/rp-15v09p01/scala/split-brain-resolver.html 关于akka如何应对脑裂，大家可以看看这篇文章。

好吧，我写一个 Avro record 的 flatten view //@邓草原: 按 JOIN 处理集合字段，能简化 KEY、VALUE、INDEX 函数，但会带来巨大的数据冗余，如果我能设计一种虚拟的多行结构呢？// 再想了一下，这些关键字是作用在 Map、List 上的，如果把 Map、List 看成是 JOIN （JPQL 是这样看的），似乎就自然了。
@邓草原
JPQL 的 KEY、VALUE、INDEX 关键字怪怪的，要实现起来不太自然呐，我去望会星空...

JPQL on Chana 用 avro projection 和 avro record flatten view 完成了基本的功能，包括初步的 join 后，我觉得 avro 可以挖掘的妙处还有很多。比如，我是不是可以把输出的结果也表达为 avro。这里涉及到一些类型推导。

JPQL on Chana 写了几个简单的 scripts 可以用来试一下基本的实时查询。 https://github.com/wandoulabs/chana/blob/master/README.rst#example-1-simple-record

JPQL on Chana 对于不是很大的数据集（比如全部能放倒内存中）；不是很复杂的查询（比如只有一个内嵌集合字段的 JOIN）；不是很在乎性能上的优化（比如每秒钟才处理一次），的场景，已经可用。后续是更仔细的性能调优，以及对已经换出内存的数据的查询等等。整个实现中，设计很重要，包括... (待续)
(续) 包括整个架构的设计理念，包括关键细节上的设计（avro record flat view 和 avro record projection）都自认为是很有意（jing）思（cai）的部分。这些设计虽然挺考验基本功，但一旦到位，整个处理会变得简洁自然。

又要写个 parser，这次是 XPath，用来定位某个 entity 更新时的 deep position，并计成 "binlog"。也许，还会顶掉 avpath。

“Chana 就是个实时的状态记录和更新系统，这点与 Storm 等分布式实时计算系统不太一样——Storm 们并不会保存用户的状态，只是不断的计算“流”过来的日志。”

对 “动态语言如何在 JVM 上实现类型优化” 感兴趣的可以下载这份 PDF 看看。
@邓草原
"On implementing multiple pluggable dynamic language frontends on the #JVM#, using the #Nashorn# runtime": Nashorn has a type system that optimizes the code by using primitive bytecode instructions where possible. Either types are proved statically or a ... http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A860991&dswid=1216

写好了一批 rollback 闭包后，然后好像找不到需要调用的地方。其实在 Chana 中，对于单个 entity (actor) 的操作并不需要用 rollback，因为成功写 "binlog" 后，直接修改 entity 就对了，而如果写 "binlog" 失败，放弃操作就是。当然写了这一堆也不是无用功，因为前提正好是“修改”操作要 lazy 化。
@邓草原
Chana 要做个较大的重构。为保持更新等操作的原子性，原来是用先简单复制一份副本的方式。其实 Akka 的 actor 模式本身可以保证在单个 entity (actor) 中某个行为的原子性，故，可以改成一个包含了回滚动作的“函数”来代替。
回复@声zzz:可以这么理解。对于 Chana，问题在于解析完请求语句后执行的时机。原来是 evaluate 前复制一个副本边 evaluate 边更新。现在是把 evaluate 过程中的实际更新动作组装成一个闭包，这样就可以自在地选择执行时机，同时也得到了最精简的 “binlog”。 //@声zzz:跟日志式文件系统有点像

Parquet 数据格式，一条记录压平后按列存储，但在同条记录里是上下文相关的？或者说，随机拿到一列，是推导不出它的位置的。甚至，它本身就像一种 binlog? #看来还是得使用字典化的 XPath 来记 binlog#

Chana 能做什么。以前，计算 x+y，你要写 var x=1, var y=2, var z=x+y，然后得到结果 3。但当 x, y 变化时，需要把这个步骤用新的值重算一遍，这需要你自己处理。而在 Chana 中，z 实时反映 x 或 y 的变化，而且，这样的 x, y 可以是成千上万上亿个，可以是嵌套数据结构，可以分布在上千台机器上。
从这个意义上来说，我们可以认为以前的 x, y 是死的。而在 Chana 中它们都是活的。这个 x, y 可以对应为一个用户，一部手机；也可以对应一草，一木。它可以记忆一段历史（timeline），也可以是观察者看到的此刻的状态（snapahot）。

这是我做实时金融计算平台时的思路。当时 (2011年) 是 4 台 128 G 内存的集群，每秒可以计算全市场的上百万指标，每个指标可按不同时间周期保持几个月（分钟线）或者有史以来（日线）的时间序列。指标由事件（股价的 Ticker 等）即时触发链式增量计算。不同的是，那时集群要自己管理。
@InfoQ
【使用Akka来优化Spark+ElasticSearch的准实时系统】最近，来自于Premium Minds的软件架构师André Camilo在博客上发表了一篇文章，介绍了他们是如何使用Akka解决准实时应用场景遇到的问题的。 http://www.infoq.com/cn/news/2015/12/akka-to-the-rescue
回复@狂徒大作:增量指，对于一个聚合性质的指标，比如 SUM ，只需计算变化的元素带来的影响，这块需要针对不同指标仔细设计增量计算公式。链式指，比如一个 MA 指标依赖于 SUM，那么当影响 SUM 的元素变化时，会触发 SUM 的变化，SUM 的变化又触发 MA 的变化。


Chana 能做什么。以前，计算 x+y，你要写 var x=1, var y=2, var z=x+y，然后得到结果 3。但当 x, y 变化时，需要把这个步骤用新的值重算一遍，这需要你自己处理。而在 Chana 中，z 实时反映 x 或 y 的变化，而且，这样的 x, y 可以是成千上万上亿个，可以是嵌套数据结构，可以分布在上千台机器上。


很多东西我已经通用化后搬到 chana ，等完成 jpql 后会把更多的尤其是时间序列指标和一些机器学习的算法接着搬过来。//@王雨舟大Boat:关注

Question 1: 
Compared with traditional SQL query. It seems that the query has status and the query result can be monitored continuously and the result is updated once some monitored values change.

Is there any differences when doing the query optimization on the Query plan? What is the special aspect for JPQL on Chana?

Ans:
The data are stored as Avro object, each avro record is an actor. When a JPQL query is applied to cluster, it will be parsed, and the applicable part (such as where clause, select related fields) will be evaluated by each record (actor) itself, and then push the minimal projection to aggregator (a singleton actor in cluster), then is evaluated by aggregator.

It's still under heavy developing, there are lots of optimization works to be done. But, you may have noticed, the README gives an example that should have worked.



回复我的评论：每条record是一个actor，是把一些hot的record放在memory里面，cold的record利用akka persistent到disk么？
是